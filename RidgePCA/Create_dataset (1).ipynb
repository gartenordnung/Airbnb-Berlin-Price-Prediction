{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0139584-cf56-4eff-a1e8-b5c1b64bf5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Dataset from detailed_listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a292dd7d-09ae-454a-ba92-1b79013e2ac8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 15:23:18.396082: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-27 15:23:18.399816: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-27 15:23:18.412058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-27 15:23:18.436164: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-27 15:23:18.436240: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-27 15:23:18.451651: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-27 15:23:19.236447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import os\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b9a77f6-1cd1-4442-91e3-6068cf7efc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8898, 79)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"detailed_listings.csv\")\n",
    "df[\"price\"] = df[\"price\"].replace('[\\$,]', '', regex=True).astype(float)\n",
    "df = df[df[\"price\"].notna()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3af48-85dd-4b2b-b370-fef4a4613fdc",
   "metadata": {},
   "source": [
    "### Refridgerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edf88ff2-a06c-4cd7-9053-ecc1c732d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make price numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0282d7bd-e43b-4f53-9f27-1a33909176a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns based on \"amenities\",\"description\",\"name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb26ae9-5e87-4002-9334-78c52be7e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_amenities_at_index(df, index):\n",
    "    raw_string = df.loc[index, \"amenities\"]\n",
    "    amenities_list = json.loads(raw_string)\n",
    "    return amenities_list\n",
    "\n",
    "def create_refrigerator_columns(df):\n",
    "    brand_column_names = {\n",
    "        'lg': 'refrigerator_lg',\n",
    "        'siemens': 'refrigerator_siemens',\n",
    "        'gaggenau': 'refrigerator_gaggenau',\n",
    "        'electrolux': 'refrigerator_electrolux',\n",
    "        'liebherr': 'refrigerator_liebherr',\n",
    "        'bosch': 'refrigerator_bosch',\n",
    "        'miele': 'refrigerator_miele',\n",
    "        'boomann': 'refrigerator_bomann',\n",
    "        'sharp': 'refrigerator_sharp',\n",
    "        'haier': 'refrigerator_haier',\n",
    "        'whirlpool': 'refrigerator_whirlpool',\n",
    "        'aeg': 'refrigerator_aeg',\n",
    "        'ikea': 'refrigerator_ikea',\n",
    "        'amazon': 'refrigerator_amazon',\n",
    "        'samsung': 'refrigerator_samsung',\n",
    "        'elektrolux': 'refrigerator_electrolux',\n",
    "        'beko': 'refrigerator_beko',\n",
    "        'beco': 'refrigerator_beko',\n",
    "        'smeg': 'refrigerator_smeg',\n",
    "        'severin': 'refrigerator_severin',\n",
    "        'teka': 'refrigerator_teka',\n",
    "        'zanussi': 'refrigerator_zanussi',\n",
    "        'panasonic': 'refrigerator_panasonic',\n",
    "        'vestel': 'refrigerator_vestel',\n",
    "        'gorenje': 'refrigerator_gorenje',\n",
    "        'diemens': 'refrigerator_siemens',\n",
    "        'bomann': 'refrigerator_bomann',\n",
    "        'amica': 'refrigerator_amica',\n",
    "        'neff': 'refrigerator_neff',\n",
    "    }\n",
    "\n",
    "    new_cols = {\n",
    "        \"has_refrigerator\": pd.Series(False, index=df.index),\n",
    "        \"refrigerator_shared\": pd.Series(False, index=df.index),\n",
    "    }\n",
    "    for col in set(brand_column_names.values()):\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    brand_keys_lower = {k.lower(): v for k, v in brand_column_names.items()}\n",
    "    fridge_terms = [\"refrigerator\", \"refridgerator\", \"fridge\", \"kühlschrank\"]\n",
    "\n",
    "    # NEW: shared fridge regex\n",
    "    shared_fridge_pattern = re.compile(\n",
    "        r\"\\b(shared|community).*(fridge|refrigerator|refridgerator|kühlschrank)|\"\n",
    "        r\"(fridge|refrigerator|refridgerator|kühlschrank).*(shared|community)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Detect has_refrigerator\n",
    "        if any(any(term in a for term in fridge_terms) for a in amenities_lower):\n",
    "            new_cols[\"has_refrigerator\"].at[idx] = True\n",
    "\n",
    "        # ✅ Detect refrigerator_shared\n",
    "        if any(shared_fridge_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"refrigerator_shared\"].at[idx] = True\n",
    "\n",
    "        # ✅ Detect brand-specific columns\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if any(term in amenity_lower for term in fridge_terms):\n",
    "                for brand_key_lower, col_name in brand_keys_lower.items():\n",
    "                    if brand_key_lower in amenity_lower:\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62906897-0075-4889-bcd4-b78c533b7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_refrigerator_brands(df):\n",
    "    # Identify all refrigerator brand columns in the DataFrame\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"refrigerator_\") and col != \"has_refrigerator\"]\n",
    "\n",
    "    # Count the number of True values per column\n",
    "    brand_counts = df[brand_columns].sum().sort_values(ascending=False)\n",
    "\n",
    "    # Return as a clean DataFrame for inspection or reporting\n",
    "    return brand_counts.reset_index().rename(columns={\"index\": \"brand_column\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed8da0f-df4a-4fcc-97f9-9eb561facd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_refrigerators_with_and_without_brand(df):\n",
    "    # Identify all refrigerator brand columns\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"refrigerator_\") and col != \"has_refrigerator\"]\n",
    "\n",
    "    # Boolean series: at least one brand column is True\n",
    "    has_brand = df[brand_columns].any(axis=1)\n",
    "\n",
    "    # Count:\n",
    "    # Listings with refrigerator and with brand\n",
    "    with_brand = ((df[\"has_refrigerator\"]) & (has_brand)).sum()\n",
    "\n",
    "    # Listings with refrigerator and without brand\n",
    "    without_brand = ((df[\"has_refrigerator\"]) & (~has_brand)).sum()\n",
    "\n",
    "    return {\"with_brand\": int(with_brand), \"without_brand\": int(without_brand)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90167ba6-97e4-4800-8fe4-0f0e2a3dc2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_brand': 396, 'without_brand': 6433}\n",
      "               brand_column  count\n",
      "0      refrigerator_siemens     72\n",
      "1        refrigerator_bosch     66\n",
      "2        refrigerator_miele     35\n",
      "3          refrigerator_aeg     33\n",
      "4     refrigerator_liebherr     29\n",
      "5      refrigerator_samsung     26\n",
      "6         refrigerator_smeg     23\n",
      "7    refrigerator_whirlpool     21\n",
      "8         refrigerator_ikea     13\n",
      "9           refrigerator_lg     11\n",
      "10        refrigerator_neff     11\n",
      "11       refrigerator_amica     10\n",
      "12        refrigerator_beko      9\n",
      "13  refrigerator_electrolux      8\n",
      "14     refrigerator_gorenje      7\n",
      "15     refrigerator_severin      4\n",
      "16       refrigerator_sharp      3\n",
      "17    refrigerator_gaggenau      3\n",
      "18      refrigerator_bomann      3\n",
      "19      refrigerator_vestel      3\n",
      "20       refrigerator_haier      3\n",
      "21     refrigerator_zanussi      2\n",
      "22   refrigerator_panasonic      1\n",
      "23        refrigerator_teka      1\n",
      "24      refrigerator_amazon      1\n",
      "25      refrigerator_shared      0\n"
     ]
    }
   ],
   "source": [
    "df = create_refrigerator_columns(df)\n",
    "brand_counts_df = count_refrigerator_brands(df)\n",
    "result = count_refrigerators_with_and_without_brand(df)\n",
    "print(result)\n",
    "print(brand_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa6c8e36-4d56-41f4-8bcf-16e802d5709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to check\n",
    "test_index = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95da279b-45b4-4eb5-a75d-2e1bbe83941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 337 | Displaying amenities and detected refrigerator brand(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    amenities  has_refrigerator  refrigerator_aeg\n",
      "337  [\"Shared backyard \\u2013 Fully fenced\", \"Portable fans\", \"Shower gel\", \"Dishes and silverware\", \"Bed linens\", \"Paid street parking off premises\", \"Stop the water while using me body soap\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Hangers\", \"AEG refrigerator\", \"Wifi\", \"Dishwasher\", \"Cooking basics\", \"Crib - available upon request\", \"Essentials\", \"Standalone high chair - available upon request\", \"Hair dryer\", \"Extra pillows and blankets\", \"Carbon monoxide alarm\", \"Central heating\", \"Gorenje induction stove\", \"Hot water kettle\", \"Self check-in\", \"Smart lock\", \"Dedicated workspace\", \"Kitchen\", \"Pack \\u2019n play/Travel crib\", \"Single level home\", \"Iron\", \"Gorenje stainless steel oven\", \"Coffee maker: french press\", \"Wine glasses\", \"Clothing storage: wardrobe\", \"HDTV with standard cable\", \"Smoke alarm\", \"Hot water\", \"Baking sheet\", \"Dining table\", \"Toaster\", \"Courtyard view\", \"Private patio or balcony\", \"Stop the water while using me shampoo\", \"Microwave\"]              True              True\n"
     ]
    }
   ],
   "source": [
    "# Identify refrigerator brand columns (excluding 'has_refrigerator')\n",
    "refrigerator_columns = [col for col in df.columns if col.startswith(\"refrigerator_\") and col != \"has_refrigerator\"]\n",
    "\n",
    "# Find all indices where any brand column is True\n",
    "indices_with_brand = df[df[refrigerator_columns].any(axis=1)].index\n",
    "\n",
    "# Take the first available index among those rows\n",
    "index_to_check = indices_with_brand[test_index]  # or loop over more if you wish\n",
    "\n",
    "# Filter to only the columns with True for this index\n",
    "true_brand_columns = [col for col in refrigerator_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display amenities, has_refrigerator, and only the brand columns that are True\n",
    "columns_to_display = [\"amenities\", \"has_refrigerator\"] + true_brand_columns\n",
    "\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected refrigerator brand(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961b0fc-0391-4b73-93af-f1fe0723637a",
   "metadata": {},
   "source": [
    "### Oven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6a8bfe7-bd95-4e2a-9489-d2aecc888485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_amenities_at_index(df, index):\n",
    "    raw_string = df.loc[index, \"amenities\"]\n",
    "    amenities_list = json.loads(raw_string)\n",
    "    return amenities_list\n",
    "\n",
    "def create_oven_columns(df):\n",
    "    # ✅ Clean trade oven brands only (adapted list, expand as needed)\n",
    "    brand_column_names = {\n",
    "        'bosch': 'oven_bosch',\n",
    "        'miele': 'oven_miele',\n",
    "        'siemens': 'oven_siemens',\n",
    "        'aeg': 'oven_aeg',\n",
    "        'neff': 'oven_neff',\n",
    "        'gaggenau': 'oven_gaggenau',\n",
    "        'smeg': 'oven_smeg',\n",
    "        'whirlpool': 'oven_whirlpool',\n",
    "        'electrolux': 'oven_electrolux',\n",
    "        'zanussi': 'oven_zanussi',\n",
    "        'beko': 'oven_beko',\n",
    "        'ikea': 'oven_ikea',\n",
    "        'haier': 'oven_haier',\n",
    "        'panasonic': 'oven_panasonic',\n",
    "        'teka': 'oven_teka',\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_oven\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in set(brand_column_names.values()):\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Lowercase brand mapping\n",
    "    brand_keys_lower = {k.lower(): v for k, v in brand_column_names.items()}\n",
    "    oven_terms = [\"oven\", \"backofen\", \"forno\", \"four\"]\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Set has_oven if any oven term found\n",
    "        if any(any(term in a for term in oven_terms) for a in amenities_lower):\n",
    "            new_cols[\"has_oven\"].at[idx] = True\n",
    "\n",
    "        # Set brand columns if oven term + brand in the same amenity\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if any(term in amenity_lower for term in oven_terms):\n",
    "                for brand_key_lower, col_name in brand_keys_lower.items():\n",
    "                    if brand_key_lower in amenity_lower:\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    # Add to df\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263cfaa3-ea94-480c-ae6f-960359491cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_oven_brands(df):\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"oven_\") and col != \"has_oven\"]\n",
    "    brand_counts = df[brand_columns].sum().sort_values(ascending=False)\n",
    "    return brand_counts.reset_index().rename(columns={\"index\": \"brand_column\", 0: \"count\"})\n",
    "\n",
    "def count_ovens_with_and_without_brand(df):\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"oven_\") and col != \"has_oven\"]\n",
    "    has_brand = df[brand_columns].any(axis=1)\n",
    "    with_brand = ((df[\"has_oven\"]) & (has_brand)).sum()\n",
    "    without_brand = ((df[\"has_oven\"]) & (~has_brand)).sum()\n",
    "    return {\"with_brand\": int(with_brand), \"without_brand\": int(without_brand)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15098ce2-eb63-4dc7-a9e5-e1013bbbf8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_brand': 260, 'without_brand': 4531}\n",
      "       brand_column  count\n",
      "0        oven_bosch     60\n",
      "1        oven_miele     52\n",
      "2      oven_siemens     52\n",
      "3          oven_aeg     31\n",
      "4         oven_neff     20\n",
      "5         oven_ikea     17\n",
      "6     oven_gaggenau      8\n",
      "7         oven_smeg      6\n",
      "8      oven_zanussi      4\n",
      "9    oven_whirlpool      4\n",
      "10        oven_beko      3\n",
      "11  oven_electrolux      2\n",
      "12        oven_teka      1\n",
      "13   oven_panasonic      0\n",
      "14       oven_haier      0\n"
     ]
    }
   ],
   "source": [
    "df = create_oven_columns(df)\n",
    "\n",
    "# Get counts\n",
    "oven_brand_counts_df = count_oven_brands(df)\n",
    "oven_counts = count_ovens_with_and_without_brand(df)\n",
    "\n",
    "print(oven_counts)\n",
    "print(oven_brand_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f5b6e49-9fa3-4189-9ede-9af9eda70c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 51 | Displaying amenities and detected oven brand(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           amenities  has_oven  oven_aeg\n",
      "51  [\"Noise decibel monitors on property\", \"Yamaha pianocraft sound system with Bluetooth and aux\", \"Drying rack for clothing\", \"Safe\", \"Portable fans\", \"Dishes and silverware\", \"Bed linens\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Books and reading material\", \"Hangers\", \"Coffee\", \"Dishwasher\", \"Cleaning products\", \"Bosch refrigerator\", \"Freezer\", \"Paid pack \\u2019n play/travel crib - available upon request\", \"Paid washer \\u2013 In unit\", \"Private backyard \\u2013 Fully fenced\", \"Bidet\", \"Cooking basics\", \"Fire extinguisher\", \"First aid kit\", \"AEG induction stove\", \"Essentials\", \"AEG oven\", \"Savon liquide de Marseille body soap\", \"Paid dryer \\u2013 In unit\", \"Hair dryer\", \"Extra pillows and blankets\", \"Carbon monoxide alarm\", \"Central heating\", \"Hot water kettle\", \"Exterior security cameras on property\", \"Coffee maker: Nespresso, pour-over coffee\", \"Self check-in\", \"Lockbox\", \"49 inch HDTV with Amazon Prime Video, Netflix, standard cable\", \"Kitchen\", \"Single level home\", \"Iron\", \"Wine glasses\", \"Free street parking\", \"High chair - always at the listing\", \"Clothing storage: wardrobe\", \"Paid crib - available upon request\", \"Hot water\", \"Smoke alarm\", \"Room-darkening shades\", \"Fast wifi \\u2013 738 Mbps\", \"Baking sheet\", \"Paid parking lot off premises\", \"Private entrance\", \"Ethernet connection\", \"Dining table\", \"Toaster\", \"Courtyard view\", \"Private patio or balcony\", \"Microwave\"]      True      True\n"
     ]
    }
   ],
   "source": [
    "# Identify oven brand columns\n",
    "oven_columns = [col for col in df.columns if col.startswith(\"oven_\") and col != \"has_oven\"]\n",
    "\n",
    "# Get indices where any oven brand was detected\n",
    "indices_with_oven_brand = df[df[oven_columns].any(axis=1)].index\n",
    "\n",
    "# Select the test index for inspection (adjust as needed)\n",
    "test_index = 0 # or another index for targeted inspection\n",
    "index_to_check = indices_with_oven_brand[test_index]\n",
    "\n",
    "# Filter columns with True for this index\n",
    "true_oven_columns = [col for col in oven_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for double-check\n",
    "columns_to_display = [\"amenities\", \"has_oven\"] + true_oven_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected oven brand(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10468613-102e-48ff-b68b-5d860c3e9f2a",
   "metadata": {},
   "source": [
    "### Stove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1197cceb-ab0a-4795-b70e-6a84f9a09804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_stove_columns(df):\n",
    "    # ✅ Stove types detection patterns\n",
    "    stove_types_patterns = {\n",
    "        \"stove_electric\": r\"\\belectric\\b\",\n",
    "        \"stove_induction\": r\"\\binduction\\b\",\n",
    "        \"stove_gas\": r\"\\bgas\\b\",\n",
    "    }\n",
    "\n",
    "    # ✅ Stove brands to detect\n",
    "    brand_column_names = {\n",
    "        'bosch': 'stove_bosch',\n",
    "        'miele': 'stove_miele',\n",
    "        'siemens': 'stove_siemens',\n",
    "        'aeg': 'stove_aeg',\n",
    "        'neff': 'stove_neff',\n",
    "        'gaggenau': 'stove_gaggenau',\n",
    "        'smeg': 'stove_smeg',\n",
    "        'whirlpool': 'stove_whirlpool',\n",
    "        'electrolux': 'stove_electrolux',\n",
    "        'zanussi': 'stove_zanussi',\n",
    "        'beko': 'stove_beko',\n",
    "        'ikea': 'stove_ikea',\n",
    "        'haier': 'stove_haier',\n",
    "        'panasonic': 'stove_panasonic',\n",
    "        'teka': 'stove_teka',\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_stove\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in set(stove_types_patterns.keys()).union(brand_column_names.values()):\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Lowercase mapping for brands\n",
    "    brand_keys_lower = {k.lower(): v for k, v in brand_column_names.items()}\n",
    "\n",
    "    # Stove detection terms\n",
    "    stove_terms_pattern = re.compile(\n",
    "        r\"\\b(stove|cooktop|herd|kochen|cooking range|cooker)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Check if stove term is present\n",
    "        if any(stove_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_stove\"].at[idx] = True\n",
    "\n",
    "            # ✅ Check for types if stove term present\n",
    "            for amenity_lower in amenities_lower:\n",
    "                if stove_terms_pattern.search(amenity_lower):\n",
    "                    for col_name, type_pattern in stove_types_patterns.items():\n",
    "                        if re.search(type_pattern, amenity_lower):\n",
    "                            new_cols[col_name].at[idx] = True\n",
    "\n",
    "                    # ✅ Check for brands if stove term present\n",
    "                    for brand_key_lower, col_name in brand_keys_lower.items():\n",
    "                        if brand_key_lower in amenity_lower:\n",
    "                            new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "828daa01-c015-4e0f-a0cb-ad552343b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_stove_columns(df)\n",
    "\n",
    "def count_stove_features(df):\n",
    "    stove_columns = [col for col in df.columns if col.startswith(\"stove_\")]\n",
    "    stove_counts = df[stove_columns].sum().sort_values(ascending=False)\n",
    "    return stove_counts.reset_index().rename(columns={\"index\": \"stove_feature\", 0: \"count\"})\n",
    "\n",
    "def count_stoves_with_and_without_features(df):\n",
    "    stove_columns = [col for col in df.columns if col.startswith(\"stove_\") and col != \"has_stove\"]\n",
    "    has_feature = df[stove_columns].any(axis=1)\n",
    "    with_feature = ((df[\"has_stove\"]) & (has_feature)).sum()\n",
    "    without_feature = ((df[\"has_stove\"]) & (~has_feature)).sum()\n",
    "    return {\"with_feature\": int(with_feature), \"without_feature\": int(without_feature)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62402cc8-e128-464d-970f-0348cbf30c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 17 | Displaying amenities and detected stove type(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       amenities  has_stove  stove_electric  stove_neff\n",
      "17  [\"Bathtub\", \"Drying rack for clothing\", \"Shower gel\", \"Dishes and silverware\", \"Garden view\", \"Bed linens\", \"Cleaning available during stay\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Coffee\", \"High chair\", \"Shampoo\", \"Children\\u2019s dinnerware\", \"Cleaning products\", \"Fast wifi \\u2013 55 Mbps\", \"Cooking basics\", \"Fire extinguisher\", \"Essentials\", \"Coffee maker\", \"Blender\", \"Outdoor playground\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Carbon monoxide alarm\", \"Hot water kettle\", \"Dedicated workspace\", \"Kitchen\", \"Pack \\u2019n play/Travel crib\", \"Iron\", \"Lake access\", \"Wine glasses\", \"Free street parking\", \"Clothing storage: wardrobe\", \"Hot water\", \"Body soap\", \"Room-darkening shades\", \"Children\\u2019s books and toys\", \"Smoke alarm\", \"Baking sheet\", \"Free parking on premises\", \"Crib\", \"Shared backyard \\u2013 Not fully fenced\", \"Host greets you\", \"Private entrance\", \"NEFF electric stove\", \"Oven\", \"Toaster\", \"Dining table\", \"Free washer \\u2013 In unit\", \"Private patio or balcony\", \"TV with standard cable\", \"Microwave\"]       True            True        True\n"
     ]
    }
   ],
   "source": [
    "# Identify stove columns\n",
    "stove_columns = [col for col in df.columns if col.startswith(\"stove_\")]\n",
    "\n",
    "# Get indices where any stove type was detected\n",
    "indices_with_stove_type = df[df[stove_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 1\n",
    "index_to_check = indices_with_stove_type[test_index]\n",
    "\n",
    "# Filter columns with True for this index\n",
    "true_stove_columns = [col for col in stove_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for validation\n",
    "columns_to_display = [\"amenities\", \"has_stove\"] + true_stove_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected stove type(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81b41f-6360-483b-b983-5831863b61bd",
   "metadata": {},
   "source": [
    "### Sound system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c780a6e-a9ef-41ed-b3db-85427e78d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_amenities_at_index(df, index):\n",
    "    raw_string = df.loc[index, \"amenities\"]\n",
    "    amenities_list = json.loads(raw_string)\n",
    "    return amenities_list\n",
    "\n",
    "def create_sound_system_columns(df):\n",
    "    # ✅ Clean trade brands for sound systems (expandable)\n",
    "    brand_column_names = {\n",
    "        'bose': 'sound_bose',\n",
    "        'sonos': 'sound_sonos',\n",
    "        'jbl': 'sound_jbl',\n",
    "        'sony': 'sound_sony',\n",
    "        'marshall': 'sound_marshall',\n",
    "        'bang & olufsen': 'sound_bang_olufsen',\n",
    "        'b&o': 'sound_bang_olufsen',\n",
    "        'yamaha': 'sound_yamaha',\n",
    "        'samsung': 'sound_samsung',\n",
    "        'lg': 'sound_lg',\n",
    "        'philips': 'sound_philips',\n",
    "        'panasonic': 'sound_panasonic',\n",
    "        'teufel': 'sound_teufel',\n",
    "        'denon': 'sound_denon',\n",
    "        'pioneer': 'sound_pioneer',\n",
    "        'onkyo': 'sound_onkyo',\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_sound_system\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in set(brand_column_names.values()):\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Lowercase brand mapping\n",
    "    brand_keys_lower = {k.lower(): v for k, v in brand_column_names.items()}\n",
    "    sound_terms = [\"sound system\", \"stereo\", \"speaker\", \"speakers\", \"lautsprecher\", \"anlage\", \"hi-fi\", \"hifi\", \"soundbar\"]\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Set has_sound_system if any sound-related term found\n",
    "        if any(any(term in a for term in sound_terms) for a in amenities_lower):\n",
    "            new_cols[\"has_sound_system\"].at[idx] = True\n",
    "\n",
    "        # Set brand columns if sound term + brand in the same amenity\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if any(term in amenity_lower for term in sound_terms):\n",
    "                for brand_key_lower, col_name in brand_keys_lower.items():\n",
    "                    if brand_key_lower in amenity_lower:\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    # Add to df\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af2fee73-283e-460a-aa14-cf1b31e42014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sound_system_brands(df):\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"sound_\") and col != \"has_sound_system\"]\n",
    "    brand_counts = df[brand_columns].sum().sort_values(ascending=False)\n",
    "    return brand_counts.reset_index().rename(columns={\"index\": \"brand_column\", 0: \"count\"})\n",
    "\n",
    "def count_sound_systems_with_and_without_brand(df):\n",
    "    brand_columns = [col for col in df.columns if col.startswith(\"sound_\") and col != \"has_sound_system\"]\n",
    "    has_brand = df[brand_columns].any(axis=1)\n",
    "    with_brand = ((df[\"has_sound_system\"]) & (has_brand)).sum()\n",
    "    without_brand = ((df[\"has_sound_system\"]) & (~has_brand)).sum()\n",
    "    return {\"with_brand\": int(with_brand), \"without_brand\": int(without_brand)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a03a34eb-2adf-48e7-89ec-498484154812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_brand': 279, 'without_brand': 751}\n",
      "          brand_column  count\n",
      "0          sound_sonos    106\n",
      "1           sound_bose     45\n",
      "2         sound_yamaha     20\n",
      "3         sound_teufel     20\n",
      "4       sound_marshall     19\n",
      "5   sound_bang_olufsen     18\n",
      "6           sound_sony     15\n",
      "7            sound_jbl     11\n",
      "8             sound_lg      9\n",
      "9        sound_pioneer      7\n",
      "10       sound_samsung      7\n",
      "11       sound_philips      5\n",
      "12     sound_panasonic      4\n",
      "13         sound_denon      3\n",
      "14         sound_onkyo      3\n"
     ]
    }
   ],
   "source": [
    "df = create_sound_system_columns(df)\n",
    "\n",
    "# Get counts\n",
    "sound_brand_counts_df = count_sound_system_brands(df)\n",
    "sound_counts = count_sound_systems_with_and_without_brand(df)\n",
    "\n",
    "print(sound_counts)\n",
    "print(sound_brand_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02f8f512-53fa-4fc2-ab52-bd03701f114f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 189 | Displaying amenities and detected sound system brand(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 amenities  has_sound_system  sound_panasonic  sound_sony\n",
      "189  [\"Portable fans\", \"Shower gel\", \"Dishes and silverware\", \"Bed linens\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"Shampoo\", \"Dishwasher\", \"Freezer\", \"Pets allowed\", \"Cooking basics\", \"Smoking allowed\", \"HDTV with Netflix, standard cable\", \"First aid kit\", \"Essentials\", \"Coffee maker\", \"Piano\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Carbon monoxide alarm\", \"Elevator\", \"Dedicated workspace\", \"Kitchen\", \"Single level home\", \"Iron\", \"Sony / Panasonic sound system with Bluetooth and aux\", \"Washer\", \"Stove\", \"Smoke alarm\", \"Body soap\", \"Hot water\", \"Record player\", \"Ethernet connection\", \"Oven\", \"Patio or balcony\", \"Microwave\"]              True             True        True\n"
     ]
    }
   ],
   "source": [
    "# Identify sound system brand columns\n",
    "sound_columns = [col for col in df.columns if col.startswith(\"sound_\") and col != \"has_sound_system\"]\n",
    "\n",
    "# Get indices where any sound system brand was detected\n",
    "indices_with_sound_brand = df[df[sound_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "index_to_check = indices_with_sound_brand[test_index]\n",
    "\n",
    "# Filter columns with True for this index\n",
    "true_sound_columns = [col for col in sound_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for validation\n",
    "columns_to_display = [\"amenities\", \"has_sound_system\"] + true_sound_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected sound system brand(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18946535-4567-450e-aaa8-95b1caad8073",
   "metadata": {},
   "source": [
    "### Coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c0e981b-755c-4564-b7a3-a19403850814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_coffee_maker_columns(df):\n",
    "    # Expanded detection patterns with regex-friendly variants\n",
    "    coffee_types_patterns = {\n",
    "        \"coffee_espresso\": r\"\\bespresso\\b\",\n",
    "        \"coffee_french_plus\": r\"\\bfrench press\\b\",\n",
    "        \"coffee_french_nespresso\": r\"\\bnespresso\\b\",\n",
    "        \"pour_over_coffee\": r\"\\bpour[- ]over( coffee)?\\b\",\n",
    "    }\n",
    "\n",
    "    new_cols = {\n",
    "        \"has_coffee_maker\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in coffee_types_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Terms for has_coffee_maker detection (expanded)\n",
    "    coffee_terms_pattern = re.compile(r\"\\b(?:coffee|kaffee|espresso|french press|nespresso|pour[- ]over(?: coffee)?)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Precise has_coffee_maker detection\n",
    "        if any(coffee_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_coffee_maker\"].at[idx] = True\n",
    "\n",
    "        # ✅ Precise per-type detection\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, pattern in coffee_types_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "118b1272-79b6-4cc5-82a6-91008da7830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_coffee_maker_types(df):\n",
    "    coffee_columns = [col for col in df.columns if col.startswith(\"coffee_\") or col == \"pour_over_coffee\"]\n",
    "    coffee_counts = df[coffee_columns].sum().sort_values(ascending=False)\n",
    "    return coffee_counts.reset_index().rename(columns={\"index\": \"coffee_type\", 0: \"count\"})\n",
    "\n",
    "def count_coffee_makers_with_and_without_types(df):\n",
    "    coffee_columns = [col for col in df.columns if col.startswith(\"coffee_\") or col == \"pour_over_coffee\"]\n",
    "    has_type = df[coffee_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_coffee_maker\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_coffee_maker\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5a87481-2881-448a-a2d5-30e739ac16fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 1857, 'without_type': 3870}\n",
      "               coffee_type  count\n",
      "0  coffee_french_nespresso    915\n",
      "1          coffee_espresso    505\n",
      "2       coffee_french_plus    386\n",
      "3         pour_over_coffee    369\n"
     ]
    }
   ],
   "source": [
    "df = create_coffee_maker_columns(df)\n",
    "\n",
    "# Get counts\n",
    "coffee_counts_df = count_coffee_maker_types(df)\n",
    "coffee_summary = count_coffee_makers_with_and_without_types(df)\n",
    "\n",
    "print(coffee_summary)\n",
    "print(coffee_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca8981d8-c7d6-4382-bb9d-c1d709f07977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 26 | Displaying amenities and detected coffee type(s) ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             amenities  has_coffee_maker  coffee_french_nespresso\n",
      "26  [\"Bathtub\", \"Drying rack for clothing\", \"Safe\", \"Portable fans\", \"Shared backyard \\u2013 Fully fenced\", \"Shower gel\", \"Dishes and silverware\", \"Bed linens\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Fast wifi \\u2013 321 Mbps\", \"Coffee\", \"Shampoo\", \"Dishwasher\", \"Cleaning products\", \"Freezer\", \"Coffee maker: Nespresso\", \"Electric stove\", \"Conditioner\", \"Cooking basics\", \"Outlet covers\", \"Fire extinguisher\", \"First aid kit\", \"Essentials\", \"Hair dryer\", \"Extra pillows and blankets\", \"Carbon monoxide alarm\", \"Central heating\", \"Hot water kettle\", \"Dedicated workspace\", \"Kitchen\", \"Single level home\", \"Iron\", \"Wine glasses\", \"Free street parking\", \"Hot water\", \"Body soap\", \"Smoke alarm\", \"Baking sheet\", \"Host greets you\", \"Clothing storage: dresser\", \"Board games\", \"Oven\", \"Toaster\", \"Dining table\", \"26 inch HDTV with Netflix, premium cable\", \"Free washer \\u2013 In unit\", \"Microwave\"]              True                     True\n"
     ]
    }
   ],
   "source": [
    "# Identify coffee columns\n",
    "coffee_columns = [col for col in df.columns if col.startswith(\"coffee_\") or col == \"pour_over_coffee\"]\n",
    "\n",
    "# Get indices where any coffee type was detected\n",
    "indices_with_coffee_type = df[df[coffee_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index for inspection\n",
    "test_index = 2\n",
    "index_to_check = indices_with_coffee_type[test_index]\n",
    "\n",
    "# Filter columns with True for this index\n",
    "true_coffee_columns = [col for col in coffee_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for validation\n",
    "columns_to_display = [\"amenities\", \"has_coffee_maker\"] + true_coffee_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected coffee type(s) ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0f115f-3685-437e-946b-4fce4849ba8d",
   "metadata": {},
   "source": [
    "### Excercise Equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7bfcff0-a58b-4b50-8e4f-0756abb7a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_exercise_equipment_columns(df):\n",
    "    # ✅ Define patterns for equipment types\n",
    "    equipment_types_patterns = {\n",
    "        \"exercise_equipment_free_weights\": r\"\\b(dumbbells?|free weights?|kettlebells?)\\b\",\n",
    "        \"exercise_equipment_elliptical\": r\"\\belliptical\\b\",\n",
    "        \"exercise_equipment_stationary_bike\": r\"\\b(stationary bike|exercise bike|spinning bike)\\b\",\n",
    "        \"exercise_equipment_yoga_mat\": r\"\\b(yoga mat|yogamat)\\b\",\n",
    "        \"exercise_equipment_workout_bench\": r\"\\b(workout bench|weight bench|training bench)\\b\",\n",
    "        \"exercise_equipment_treadmill\": r\"\\btreadmill\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_exercise_equipment\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in equipment_types_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General terms for 'has_exercise_equipment'\n",
    "    exercise_terms_pattern = re.compile(\n",
    "        r\"\\b(gym|fitness|exercise|workout|training|dumbbell|weights?|kettlebell|elliptical|bike|yoga|treadmill|rowing)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Set has_exercise_equipment if any relevant term detected\n",
    "        if any(exercise_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_exercise_equipment\"].at[idx] = True\n",
    "\n",
    "        # ✅ Set equipment type columns precisely\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if exercise_terms_pattern.search(amenity_lower):\n",
    "                for col_name, pattern in equipment_types_patterns.items():\n",
    "                    if re.search(pattern, amenity_lower):\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "386203e1-654b-474d-9227-5b41a4c33872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_exercise_equipment_types(df):\n",
    "    equipment_columns = [col for col in df.columns if col.startswith(\"exercise_equipment_\")]\n",
    "    equipment_counts = df[equipment_columns].sum().sort_values(ascending=False)\n",
    "    return equipment_counts.reset_index().rename(columns={\"index\": \"equipment_type\", 0: \"count\"})\n",
    "\n",
    "def count_exercise_equipment_with_and_without_types(df):\n",
    "    equipment_columns = [col for col in df.columns if col.startswith(\"exercise_equipment_\") and col != \"has_exercise_equipment\"]\n",
    "    has_type = df[equipment_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_exercise_equipment\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_exercise_equipment\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7238cd1e-4ef8-4b5b-b088-80b8daa2c09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 220, 'without_type': 403}\n",
      "                       equipment_type  count\n",
      "0         exercise_equipment_yoga_mat    147\n",
      "1     exercise_equipment_free_weights    126\n",
      "2       exercise_equipment_elliptical     26\n",
      "3  exercise_equipment_stationary_bike     21\n",
      "4    exercise_equipment_workout_bench     17\n",
      "5        exercise_equipment_treadmill     17\n"
     ]
    }
   ],
   "source": [
    "df = create_exercise_equipment_columns(df)\n",
    "\n",
    "# Get counts\n",
    "equipment_counts_df = count_exercise_equipment_types(df)\n",
    "equipment_summary = count_exercise_equipment_with_and_without_types(df)\n",
    "\n",
    "print(equipment_summary)\n",
    "print(equipment_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28131562-fed8-4c9a-b4ab-b2d00e3e9235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 423 | Displaying amenities and detected exercise equipment features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 amenities  has_exercise_equipment  exercise_equipment_free_weights  exercise_equipment_yoga_mat\n",
      "423  [\"Bathtub\", \"Drying rack for clothing\", \"Shower gel\", \"Dishes and silverware\", \"Bed linens\", \"Books and reading material\", \"Refrigerator\", \"Coffee\", \"Wifi\", \"Shampoo\", \"Dishwasher\", \"Freezer\", \"Cooking basics\", \"First aid kit\", \"Essentials\", \"Exercise equipment: free weights, yoga mat\", \"Coffee maker: pour-over coffee\", \"Blender\", \"Hair dryer\", \"Heating\", \"Hot water kettle\", \"Elevator\", \"Kitchen\", \"Stove\", \"Smoke alarm\", \"Body soap\", \"Hot water\", \"Host greets you\", \"Oven\", \"Toaster\", \"Dining table\", \"Microwave\"]                    True                             True                         True\n"
     ]
    }
   ],
   "source": [
    "# Identify exercise equipment columns\n",
    "equipment_columns = [col for col in df.columns if col.startswith(\"exercise_equipment_\")]\n",
    "\n",
    "# Get indices where any equipment detected\n",
    "indices_with_equipment = df[df[equipment_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "index_to_check = indices_with_equipment[test_index]\n",
    "\n",
    "# Filter columns with True for this row\n",
    "true_equipment_columns = [col for col in equipment_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for QA\n",
    "columns_to_display = [\"amenities\", \"has_exercise_equipment\"] + true_equipment_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected exercise equipment features ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e6cf5-7077-4ae2-8dd7-16749dc82c55",
   "metadata": {},
   "source": [
    "### Game Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db938e53-cec1-4c43-984a-b0369e99488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_game_console_columns(df):\n",
    "    # ✅ Define regex patterns for each console\n",
    "    console_patterns = {\n",
    "        \"ps2\": r\"\\b(ps2|playstation 2)\\b\",\n",
    "        \"ps3\": r\"\\b(ps3|playstation 3)\\b\",\n",
    "        \"ps4\": r\"\\b(ps4|playstation 4)\\b\",\n",
    "        \"ps5\": r\"\\b(ps5|playstation 5)\\b\",\n",
    "        \"xbox360\": r\"\\b(xbox 360|xbox360)\\b\",\n",
    "        \"xboxone\": r\"\\b(xbox one|xboxone)\\b\",\n",
    "        \"nintendoswitch\": r\"\\b(nintendo switch|switch)\\b\",\n",
    "        \"wii\": r\"\\b(wii|nintendo wii)\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_game_console\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in console_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General console detection pattern\n",
    "    console_terms_pattern = re.compile(\n",
    "        r\"\\b(playstation|ps[2-5]|xbox|nintendo|switch|wii|game console|gaming console)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Set has_game_console if general term detected\n",
    "        if any(console_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_game_console\"].at[idx] = True\n",
    "\n",
    "        # ✅ Set individual console columns if detected\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if console_terms_pattern.search(amenity_lower):\n",
    "                for col_name, pattern in console_patterns.items():\n",
    "                    if re.search(pattern, amenity_lower):\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8bc972f-aff8-4719-abe6-880449c9781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_game_console_types(df):\n",
    "    console_columns = [\"ps2\", \"ps3\", \"ps4\", \"ps5\", \"xbox360\", \"xboxone\", \"nintendoswitch\", \"wii\"]\n",
    "    console_counts = df[console_columns].sum().sort_values(ascending=False)\n",
    "    return console_counts.reset_index().rename(columns={\"index\": \"console_type\", 0: \"count\"})\n",
    "\n",
    "def count_game_consoles_with_and_without_type(df):\n",
    "    console_columns = [\"ps2\", \"ps3\", \"ps4\", \"ps5\", \"xbox360\", \"xboxone\", \"nintendoswitch\", \"wii\"]\n",
    "    has_type = df[console_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_game_console\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_game_console\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72c8e33a-423f-43a3-a07f-e9d019ba9c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 88, 'without_type': 81}\n",
      "     console_type  count\n",
      "0             ps4     35\n",
      "1  nintendoswitch     21\n",
      "2             ps3     11\n",
      "3             ps5     11\n",
      "4             wii     11\n",
      "5         xboxone      7\n",
      "6         xbox360      3\n",
      "7             ps2      2\n"
     ]
    }
   ],
   "source": [
    "df = create_game_console_columns(df)\n",
    "\n",
    "# Get counts\n",
    "console_counts_df = count_game_console_types(df)\n",
    "console_summary = count_game_consoles_with_and_without_type(df)\n",
    "\n",
    "print(console_summary)\n",
    "print(console_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c33a3a6e-a08b-4170-9473-3a16e370be40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 1588 | Displaying amenities and detected game console features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                amenities  has_game_console   ps4\n",
      "1588  [\"Bathtub\", \"LG sound system\", \"Dishes and silverware\", \"Bed linens\", \"Long term stays allowed\", \"HDTV\", \"Hangers\", \"Refrigerator\", \"Wifi\", \"Dishwasher\", \"Game console: PS4\", \"Freezer\", \"Cooking basics\", \"Crib - available upon request\", \"Essentials\", \"Standalone high chair - available upon request\", \"Blender\", \"Piano\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Hot water kettle\", \"Clothing storage: closet\", \"Dedicated workspace\", \"Kitchen\", \"Iron\", \"Wine glasses\", \"Washer\", \"Hot water\", \"Smoke alarm\", \"Room-darkening shades\", \"Host greets you\", \"Oven\", \"Dining table\", \"Changing table - available upon request\", \"Microwave\"]              True  True\n"
     ]
    }
   ],
   "source": [
    "# Identify console columns\n",
    "console_columns = [\"ps2\", \"ps3\", \"ps4\", \"ps5\", \"xbox360\", \"xboxone\", \"nintendoswitch\", \"wii\"]\n",
    "\n",
    "# Get indices where any console detected\n",
    "indices_with_console = df[df[console_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "index_to_check = indices_with_console[test_index]\n",
    "\n",
    "# Columns with True for this row\n",
    "true_console_columns = [col for col in console_columns if df.at[index_to_check, col] == True]\n",
    "\n",
    "# Display for QA\n",
    "columns_to_display = [\"amenities\", \"has_game_console\"] + true_console_columns\n",
    "df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected game console features ===\")\n",
    "print(df_check.to_string(max_colwidth=1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1da67d4-cfde-4157-9629-8b3c4cb7d22a",
   "metadata": {},
   "source": [
    "### TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13b94e12-23e3-4084-98f1-6a8e42ced49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_amenities_at_index(df, index):\n",
    "    raw_string = df.loc[index, \"amenities\"]\n",
    "    amenities_list = json.loads(raw_string)\n",
    "    return amenities_list\n",
    "\n",
    "def create_tv_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_tv\": pd.Series(False, index=df.index),\n",
    "        \"tv_size_inch\": pd.Series(None, index=df.index, dtype=float)\n",
    "    }\n",
    "\n",
    "    # TV detection pattern (detects tv, hdtv, smart tv, etc.)\n",
    "    tv_terms_pattern = re.compile(\n",
    "        r\"\\b(tv|television|smart tv|hdtv)\\b\"\n",
    "    )\n",
    "\n",
    "    # Pattern to extract TV size in inches\n",
    "    tv_size_pattern = re.compile(\n",
    "        r\"(\\d{2,3}(?:[.,]\\d+)?)\\s*(?:\\\"|inch|in|”)\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        found_tv = False\n",
    "        sizes = []\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Check if TV is mentioned\n",
    "            if tv_terms_pattern.search(amenity):\n",
    "                found_tv = True\n",
    "\n",
    "                # Attempt to extract size\n",
    "                size_match = tv_size_pattern.search(amenity)\n",
    "                if size_match:\n",
    "                    size_str = size_match.group(1).replace(\",\", \".\")\n",
    "                    try:\n",
    "                        size_float = float(size_str)\n",
    "                        sizes.append(size_float)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "        if found_tv:\n",
    "            new_cols[\"has_tv\"].at[idx] = True\n",
    "\n",
    "            # If multiple sizes are found, take the largest (most likely the primary TV)\n",
    "            if sizes:\n",
    "                new_cols[\"tv_size_inch\"].at[idx] = max(sizes)\n",
    "\n",
    "    # Add to df\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7f5fa44-514b-4d27-8453-d57700e408cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_tv_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46e130b7-f105-4a78-a0e9-97cf12d2d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tv_summary(df):\n",
    "    has_tv = df[\"has_tv\"] == True\n",
    "    has_size = df[\"tv_size_inch\"].notna()\n",
    "\n",
    "    with_size = (has_tv & has_size).sum()\n",
    "    without_size = (has_tv & ~has_size).sum()\n",
    "    total_tv = has_tv.sum()\n",
    "\n",
    "    return {\n",
    "        \"total_tv\": int(total_tv),\n",
    "        \"with_size\": int(with_size),\n",
    "        \"without_size\": int(without_size)\n",
    "    }\n",
    "\n",
    "def count_tv_size_distribution(df, bins=None):\n",
    "    \"\"\"\n",
    "    Returns a distribution of TV sizes (using bins if provided).\n",
    "    \"\"\"\n",
    "    tv_sizes = df.loc[df[\"tv_size_inch\"].notna(), \"tv_size_inch\"]\n",
    "    if bins:\n",
    "        return pd.cut(tv_sizes, bins=bins).value_counts().sort_index()\n",
    "    else:\n",
    "        return tv_sizes.value_counts().sort_index()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15f36512-d0eb-477b-9498-518d35e6ed4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_tv': 6085, 'with_size': 825, 'without_size': 5260}\n",
      "tv_size_inch\n",
      "16.0       1\n",
      "23.0       2\n",
      "24.0       7\n",
      "25.0       1\n",
      "26.0       4\n",
      "27.0       2\n",
      "28.0       4\n",
      "30.0      10\n",
      "31.0       3\n",
      "32.0     106\n",
      "33.0       2\n",
      "34.0       5\n",
      "35.0      10\n",
      "37.0       2\n",
      "38.0       2\n",
      "39.0       4\n",
      "40.0      70\n",
      "41.0       5\n",
      "42.0      58\n",
      "43.0     121\n",
      "44.0       2\n",
      "45.0      11\n",
      "46.0      11\n",
      "47.0       6\n",
      "48.0      15\n",
      "49.0      12\n",
      "50.0      72\n",
      "52.0       7\n",
      "53.0       1\n",
      "54.0       3\n",
      "55.0     125\n",
      "56.0       2\n",
      "58.0       5\n",
      "60.0      14\n",
      "65.0      66\n",
      "70.0       8\n",
      "74.0       1\n",
      "75.0      12\n",
      "77.0       2\n",
      "80.0       3\n",
      "81.0       1\n",
      "82.0       1\n",
      "85.0       4\n",
      "86.0       1\n",
      "98.0       1\n",
      "100.0      2\n",
      "108.0      8\n",
      "110.0      2\n",
      "120.0      2\n",
      "140.0      1\n",
      "150.0      2\n",
      "164.0      1\n",
      "300.0      1\n",
      "400.0      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get TV counts summary\n",
    "tv_summary = count_tv_summary(df)\n",
    "\n",
    "# Get TV size distribution (optional)\n",
    "tv_size_distribution = count_tv_size_distribution(df)\n",
    "\n",
    "# Display results\n",
    "print(tv_summary)\n",
    "print(tv_size_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9bdf2c6-7c83-4ab2-92bc-930ebf910748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 20 | Displaying amenities and detected TV features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        amenities  has_tv  tv_size_inch\n",
      "20  [\"Bathtub\", \"Private sauna\", \"Drying rack for clothing\", \"Dishes and silverware\", \"City skyline view\", \"Bed linens\", \"Paid street parking off premises\", \"Outdoor dining area\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Park view\", \"Wifi\", \"42 inch HDTV with Netflix, premium cable\", \"Dishwasher\", \"Cleaning products\", \"Window guards\", \"Freezer\", \"Electric stove\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Ruark sound system with Bluetooth and aux\", \"Central heating\", \"Elevator\", \"Clothing storage: closet\", \"Kitchen\", \"Single level home\", \"Free washer\", \"Wine glasses\", \"Hot water\", \"Body soap\", \"Smoke alarm\", \"Baking sheet\", \"Host greets you\", \"Board games\", \"Oven\", \"Toaster\", \"Dining table\", \"Private patio or balcony\", \"Exercise equipment: elliptical\"]    True          42.0\n"
     ]
    }
   ],
   "source": [
    "# Filter for rows with TV\n",
    "indices_with_tv = df[df[\"tv_size_inch\"].notna()].index\n",
    "\n",
    "# Pick the nth row to inspect\n",
    "test_index = 0\n",
    "if test_index < len(indices_with_tv):\n",
    "    index_to_check = indices_with_tv[test_index]\n",
    "    df_check = df.loc[[index_to_check], [\"amenities\", \"has_tv\", \"tv_size_inch\"]]\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected TV features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_tv)} rows with has_tv == True; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b64358-2bb8-40af-9edc-515630912023",
   "metadata": {},
   "source": [
    "### Streaming Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a1d98e8-62d0-463d-bacf-1184ec35b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_streaming_provider_columns(df):\n",
    "    # Streaming services detection patterns\n",
    "    streaming_patterns = {\n",
    "        \"streaming_netflix\": r\"\\b(netflix)\\b\",\n",
    "        \"streaming_amazon_prime_video\": r\"\\b(amazon prime video|prime video|amazon prime)\\b\",\n",
    "        \"streaming_apple_tv\": r\"\\b(apple tv|appletv)\\b\",\n",
    "        \"streaming_disney_plus\": r\"(disney\\+|disney plus|disney\\s*\\+)\"\n",
    "\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_streaming_provider\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in streaming_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General detection pattern for has_streaming_provider\n",
    "    streaming_terms_pattern = re.compile(\n",
    "    r\"(netflix|amazon prime video|prime video|amazon prime|apple tv|appletv|disney\\+|disney plus|disney\\s*\\+)\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Flag has_streaming_provider if any relevant term detected\n",
    "        if any(streaming_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_streaming_provider\"].at[idx] = True\n",
    "\n",
    "        # Flag specific streaming providers\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if streaming_terms_pattern.search(amenity_lower):\n",
    "                for col_name, pattern in streaming_patterns.items():\n",
    "                    if re.search(pattern, amenity_lower):\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9a65f01-47fd-44a6-af66-424ae220f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_streaming_provider_types(df):\n",
    "    streaming_columns = [col for col in df.columns if col.startswith(\"streaming_\")]\n",
    "    streaming_counts = df[streaming_columns].sum().sort_values(ascending=False)\n",
    "    return streaming_counts.reset_index().rename(columns={\"index\": \"streaming_provider\", 0: \"count\"})\n",
    "\n",
    "def count_streaming_providers_with_and_without_types(df):\n",
    "    streaming_columns = [col for col in df.columns if col.startswith(\"streaming_\") and col != \"has_streaming_provider\"]\n",
    "    has_type = df[streaming_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_streaming_provider\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_streaming_provider\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f195edd-1ddf-4dee-a0be-0ab6e7e1526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 520, 'without_type': 0}\n",
      "             streaming_provider  count\n",
      "0             streaming_netflix    454\n",
      "1  streaming_amazon_prime_video    252\n",
      "2         streaming_disney_plus     97\n",
      "3            streaming_apple_tv     93\n"
     ]
    }
   ],
   "source": [
    "df = create_streaming_provider_columns(df)\n",
    "\n",
    "# Get counts\n",
    "streaming_counts_df = count_streaming_provider_types(df)\n",
    "streaming_summary = count_streaming_providers_with_and_without_types(df)\n",
    "\n",
    "print(streaming_summary)\n",
    "print(streaming_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f1dd843-c706-4769-ad97-4d7964fdefef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 22 | Displaying amenities and detected streaming providers ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            amenities  has_streaming_provider  streaming_netflix  streaming_amazon_prime_video  streaming_disney_plus\n",
      "22  [\"Bathtub\", \"Canal view\", \"Drying rack for clothing\", \"Dishes and silverware\", \"Bed linens\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Dishwasher\", \"Cleaning products\", \"49 inch HDTV with Amazon Prime Video, Disney+, Netflix\", \"Freezer\", \"Bose SoundLink Mini II Bluetooth sound system\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Blender\", \"Heating\", \"Carbon monoxide alarm\", \"Hot water kettle\", \"Waterfront\", \"Dedicated workspace\", \"Kitchen\", \"Iron\", \"Wine glasses\", \"Washer\", \"Fast wifi \\u2013 104 Mbps\", \"Stove\", \"Smoke alarm\", \"Body soap\", \"Hot water\", \"Baking sheet\", \"Host greets you\", \"Oven\", \"Toaster\", \"Dining table\", \"Private patio or balcony\", \"Microwave\"]                    True               True                          True                   True\n"
     ]
    }
   ],
   "source": [
    "# Identify streaming columns\n",
    "streaming_columns = [col for col in df.columns if col.startswith(\"streaming_\")]\n",
    "\n",
    "# Get indices where any streaming service is detected\n",
    "indices_with_streaming = df[df[\"has_streaming_provider\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 2\n",
    "if test_index < len(indices_with_streaming):\n",
    "    index_to_check = indices_with_streaming[test_index]\n",
    "    true_streaming_columns = [col for col in streaming_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_streaming_provider\"] + true_streaming_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected streaming providers ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_streaming)} rows with has_streaming_provider == True; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284519a-3d92-4335-864d-83ba0e23d01e",
   "metadata": {},
   "source": [
    "### Wardrobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "085603dc-bac9-4514-a1e9-ee3fe6eb4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_clothing_storage_columns(df):\n",
    "    # Clothing storage patterns\n",
    "    clothing_patterns = {\n",
    "        \"clothing_storage_closet\": r\"\\bcloset\\b\",\n",
    "        \"clothing_storage_wardrobe\": r\"\\bwardrobe\\b\",\n",
    "        \"clothing_storage_walk_in\": r\"\\bwalk[- ]?in\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_clothing_storage\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in clothing_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General detection pattern for has_clothing_storage\n",
    "    storage_terms_pattern = re.compile(\n",
    "        r\"\\b(clothing storage|closet|wardrobe|walk[- ]?in)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Flag has_clothing_storage if any relevant term detected\n",
    "        if any(storage_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_clothing_storage\"].at[idx] = True\n",
    "\n",
    "        # Flag specific types\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if storage_terms_pattern.search(amenity_lower):\n",
    "                for col_name, pattern in clothing_patterns.items():\n",
    "                    if re.search(pattern, amenity_lower):\n",
    "                        new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10bbfd46-cbf9-4b16-9055-bcaf8471e440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_clothing_storage_types(df):\n",
    "    clothing_columns = [col for col in df.columns if col.startswith(\"clothing_storage_\")]\n",
    "    clothing_counts = df[clothing_columns].sum().sort_values(ascending=False)\n",
    "    return clothing_counts.reset_index().rename(columns={\"index\": \"clothing_storage_type\", 0: \"count\"})\n",
    "\n",
    "def count_clothing_storage_with_and_without_types(df):\n",
    "    clothing_columns = [col for col in df.columns if col.startswith(\"clothing_storage_\") and col != \"has_clothing_storage\"]\n",
    "    has_type = df[clothing_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_clothing_storage\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_clothing_storage\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d84903ab-ebcc-40ee-881f-d1ad9f191e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 2293, 'without_type': 1921}\n",
      "       clothing_storage_type  count\n",
      "0  clothing_storage_wardrobe   1672\n",
      "1    clothing_storage_closet    836\n",
      "2   clothing_storage_walk_in    117\n"
     ]
    }
   ],
   "source": [
    "df = create_clothing_storage_columns(df)\n",
    "\n",
    "# Get counts\n",
    "clothing_counts_df = count_clothing_storage_types(df)\n",
    "clothing_summary = count_clothing_storage_with_and_without_types(df)\n",
    "\n",
    "print(clothing_summary)\n",
    "print(clothing_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd771a68-3db5-4f85-8ba7-ef11ea9db1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 7 | Displaying amenities and detected clothing storage features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               amenities  has_clothing_storage  clothing_storage_closet\n",
      "7  [\"Bathtub\", \"Safe\", \"Portable fans\", \"Dishes and silverware\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"TV\", \"Hangers\", \"Refrigerator\", \"Wifi\", \"High chair\", \"Dishwasher\", \"Children\\u2019s dinnerware\", \"Cleaning products\", \"Freezer\", \"Pets allowed\", \"Hammock\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Outdoor playground\", \"Hair dryer\", \"Heating\", \"Babysitter recommendations\", \"Hot water kettle\", \"Clothing storage: closet\", \"Dedicated workspace\", \"Kitchen\", \"Outdoor furniture\", \"Single level home\", \"Iron\", \"Wine glasses\", \"Mosquito net\", \"Backyard\", \"Stove\", \"Hot water\", \"Smoke alarm\", \"Children\\u2019s books and toys\", \"Crib\", \"Oven\", \"Toaster\", \"Dining table\", \"Free washer \\u2013 In unit\", \"Microwave\"]                  True                     True\n"
     ]
    }
   ],
   "source": [
    "# Identify clothing storage columns\n",
    "clothing_columns = [col for col in df.columns if col.startswith(\"clothing_storage_\")]\n",
    "\n",
    "# Get indices where clothing storage detected\n",
    "indices_with_clothing = df[df[\"has_clothing_storage\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 1\n",
    "if test_index < len(indices_with_clothing):\n",
    "    index_to_check = indices_with_clothing[test_index]\n",
    "    true_clothing_columns = [col for col in clothing_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_clothing_storage\"] + true_clothing_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected clothing storage features ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_clothing)} rows with has_clothing_storage == True; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54839c4-d5a5-4b2b-b203-be7a552bf6df",
   "metadata": {},
   "source": [
    "### Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0244f54-59e8-4e95-8dfe-41149a86e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_parking_columns(df):\n",
    "    # Parking patterns\n",
    "    parking_patterns = {\n",
    "        \"parking_free_carport\": r\"\\bfree carport\\b\",\n",
    "        \"parking_free_driveway\": r\"\\bfree driveway parking\\b\",\n",
    "        \"parking_free_garage\": r\"\\bfree parking garage\\b\",\n",
    "        \"parking_free_residential_garage\": r\"\\bfree residential garage\\b\",\n",
    "        \"parking_free_street\": r\"\\bfree street parking\\b\",\n",
    "        \"parking_paid_garage\": r\"\\bpaid parking garage\\b\",\n",
    "        \"parking_paid_lot\": r\"\\bpaid parking lot\\b\",\n",
    "        \"parking_paid\": r\"\\bpaid parking\\b\",\n",
    "        \"parking_paid_street\": r\"\\bpaid street parking\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_parking\": pd.Series(False, index=df.index),\n",
    "        \"parking_on_premises\": pd.Series(False, index=df.index),\n",
    "        \"parking_off_premises\": pd.Series(False, index=df.index),\n",
    "    }\n",
    "    for col in parking_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # General parking detection\n",
    "    parking_terms_pattern = re.compile(\n",
    "        r\"\\b(parking|carport|driveway|garage|street)\\b\"\n",
    "    )\n",
    "    on_premises_pattern = re.compile(r\"\\bon[- ]premises\\b\")\n",
    "    off_premises_pattern = re.compile(r\"\\boff[- ]premises\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Check if any parking mention exists\n",
    "        if any(parking_terms_pattern.search(a) for a in amenities_lower):\n",
    "            new_cols[\"has_parking\"].at[idx] = True\n",
    "\n",
    "        # Check for on-premises / off-premises\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if on_premises_pattern.search(amenity_lower):\n",
    "                new_cols[\"parking_on_premises\"].at[idx] = True\n",
    "            if off_premises_pattern.search(amenity_lower):\n",
    "                new_cols[\"parking_off_premises\"].at[idx] = True\n",
    "\n",
    "            # Flag detailed parking types\n",
    "            for col_name, pattern in parking_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    # Add columns to df\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "836ee19e-6800-436a-9263-75b82f848432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parking_types(df):\n",
    "    parking_columns = [col for col in df.columns if col.startswith(\"parking_\")]\n",
    "    parking_counts = df[parking_columns].sum().sort_values(ascending=False)\n",
    "    return parking_counts.reset_index().rename(columns={\"index\": \"parking_type\", 0: \"count\"})\n",
    "\n",
    "def count_parking_with_and_without_types(df):\n",
    "    parking_columns = [col for col in df.columns if col.startswith(\"parking_\") and col != \"has_parking\"]\n",
    "    has_type = df[parking_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_parking\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_parking\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "737ff259-614f-4a4f-aeac-d1644b563ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 5234, 'without_type': 0}\n",
      "                       parking_type  count\n",
      "0               parking_free_street   2391\n",
      "1               parking_on_premises   2212\n",
      "2              parking_off_premises   1908\n",
      "3                      parking_paid   1860\n",
      "4               parking_paid_street    901\n",
      "5                  parking_paid_lot    215\n",
      "6               parking_paid_garage    207\n",
      "7             parking_free_driveway     50\n",
      "8   parking_free_residential_garage     27\n",
      "9               parking_free_garage     10\n",
      "10             parking_free_carport      9\n"
     ]
    }
   ],
   "source": [
    "df = create_parking_columns(df)\n",
    "\n",
    "# Get counts\n",
    "parking_counts_df = count_parking_types(df)\n",
    "parking_summary = count_parking_with_and_without_types(df)\n",
    "\n",
    "print(parking_summary)\n",
    "print(parking_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ab13bae-c836-4849-8958-3027d9ba26b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 21 | Displaying amenities and detected parking features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           amenities  has_parking  parking_off_premises  parking_paid\n",
      "21  [\"Drying rack for clothing\", \"Portable fans\", \"Shower gel\", \"Dishes and silverware\", \"City skyline view\", \"Bed linens\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Outdoor dining area\", \"Refrigerator\", \"Hangers\", \"Fast wifi \\u2013 213 Mbps\", \"Shampoo\", \"Dishwasher\", \"Cleaning products\", \"Freezer\", \"Electric stove\", \"Conditioner\", \"Bidet\", \"Yamaha sound system with Bluetooth and aux\", \"Cooking basics\", \"55 inch HDTV with Amazon Prime Video, Apple TV, Netflix\", \"Essentials\", \"Free dryer \\u2013 In building\", \"Extra pillows and blankets\", \"Hair dryer\", \"Central heating\", \"Hot water kettle\", \"Coffee maker: Nespresso, pour-over coffee\", \"Bread maker\", \"Self check-in\", \"Dedicated workspace\", \"Smart lock\", \"Kitchen\", \"Outdoor furniture\", \"Iron\", \"Paid parking off premises\", \"Wine glasses\", \"Free washer \\u2013 In building\", \"Hot water\", \"Body soap\", \"Room-darkening shades\", \"Baking sheet\", \"Ethernet connection\", \"Oven\", \"Toaster\", \"Dining table\", \"Private patio or balcony\", \"Microwave\"]         True                  True          True\n"
     ]
    }
   ],
   "source": [
    "# Identify parking columns\n",
    "parking_columns = [col for col in df.columns if col.startswith(\"parking_\")]\n",
    "\n",
    "# Get indices where parking detected\n",
    "indices_with_parking = df[df[\"has_parking\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 10\n",
    "if test_index < len(indices_with_parking):\n",
    "    index_to_check = indices_with_parking[test_index]\n",
    "    true_parking_columns = [col for col in parking_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_parking\"] + true_parking_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected parking features ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_parking)} rows with has_parking == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f80a6002-c461-4368-9ef9-86fbc03e29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_outdoor_columns(df):\n",
    "    # Explicit patterns for detection\n",
    "    outdoor_patterns = {\n",
    "        \"outdoor_dining_area\": r\"outdoor dining area\",\n",
    "        \"outdoor_furniture\": r\"outdoor furniture\",\n",
    "        \"outdoor_kitchen\": r\"outdoor kitchen\",\n",
    "        \"outdoor_playground\": r\"outdoor playground\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_outdoor\": pd.Series(False, index=df.index),\n",
    "        \"outdoor_pool_shared\": pd.Series(False, index=df.index),\n",
    "        \"outdoor_pool_private\": pd.Series(False, index=df.index),\n",
    "    }\n",
    "    for col in outdoor_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Pool patterns\n",
    "    shared_pool_pattern = re.compile(r\"\\b(shared outdoor pool|community pool|shared pool)\\b\")\n",
    "    private_pool_pattern = re.compile(r\"\\b(outdoor pool|private outdoor pool|pool)\\b\")  # Keep \"pool\" last for broad catch\n",
    "\n",
    "    # Phrases for has_outdoor detection\n",
    "    outdoor_terms = [\n",
    "        \"outdoor dining area\",\n",
    "        \"outdoor furniture\",\n",
    "        \"outdoor kitchen\",\n",
    "        \"outdoor playground\",\n",
    "        \"outdoor pool\",\n",
    "        \"shared outdoor pool\",\n",
    "        \"private outdoor pool\",\n",
    "        \"community pool\",\n",
    "        \"shared pool\",\n",
    "        \"pool\",\n",
    "    ]\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # ✅ Set has_outdoor only if one of the clear outdoor terms is present\n",
    "        if any(any(term in a for term in outdoor_terms) for a in amenities_lower):\n",
    "            new_cols[\"has_outdoor\"].at[idx] = True\n",
    "\n",
    "        # ✅ Check shared/private pools\n",
    "        for amenity_lower in amenities_lower:\n",
    "            if shared_pool_pattern.search(amenity_lower):\n",
    "                new_cols[\"outdoor_pool_shared\"].at[idx] = True\n",
    "            elif private_pool_pattern.search(amenity_lower):\n",
    "                # Only mark as private if not marked as shared\n",
    "                if not shared_pool_pattern.search(amenity_lower):\n",
    "                    new_cols[\"outdoor_pool_private\"].at[idx] = True\n",
    "\n",
    "            # ✅ Check specific features\n",
    "            for col_name, pattern in outdoor_patterns.items():\n",
    "                if pattern in amenity_lower:\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f500e13b-30b4-4a4d-89a5-b31f88dcb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outdoor_types(df):\n",
    "    outdoor_columns = [col for col in df.columns if col.startswith(\"outdoor_\")]\n",
    "    outdoor_counts = df[outdoor_columns].sum().sort_values(ascending=False)\n",
    "    return outdoor_counts.reset_index().rename(columns={\"index\": \"outdoor_type\", 0: \"count\"})\n",
    "\n",
    "def count_outdoor_with_and_without_types(df):\n",
    "    outdoor_columns = [col for col in df.columns if col.startswith(\"outdoor_\") and col != \"has_outdoor\"]\n",
    "    has_type = df[outdoor_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_outdoor\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_outdoor\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8e19096-7da1-43eb-afa3-44542eb16042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 2160, 'without_type': 28}\n",
      "           outdoor_type  count\n",
      "0   outdoor_dining_area   1536\n",
      "1     outdoor_furniture   1315\n",
      "2    outdoor_playground    444\n",
      "3  outdoor_pool_private    116\n",
      "4       outdoor_kitchen     32\n",
      "5   outdoor_pool_shared     22\n"
     ]
    }
   ],
   "source": [
    "df = create_outdoor_columns(df)\n",
    "\n",
    "# Get counts\n",
    "outdoor_counts_df = count_outdoor_types(df)\n",
    "outdoor_summary = count_outdoor_with_and_without_types(df)\n",
    "\n",
    "print(outdoor_summary)\n",
    "print(outdoor_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57ce484d-9985-4a83-9a8e-8d934a0b0849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 11 | Displaying amenities and detected outdoor features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               amenities  has_outdoor  outdoor_dining_area  outdoor_furniture\n",
      "11  [\"Bathtub\", \"Drying rack for clothing\", \"Dishes and silverware\", \"Garden view\", \"Bed linens\", \"Outdoor dining area\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"Ceiling fan\", \"Electric stove\", \"Private backyard \\u2013 Fully fenced\", \"Cooking basics\", \"Coffee maker: pour-over coffee\", \"Extra pillows and blankets\", \"Heating\", \"Hot water kettle\", \"Dedicated workspace\", \"Kitchen\", \"Outdoor furniture\", \"Wine glasses\", \"Free street parking\", \"Free washer \\u2013 In building\", \"Smoke alarm\", \"Hot water\", \"Room-darkening shades\", \"Baking sheet\", \"Oven\", \"Dining table\", \"Private patio or balcony\", \"TV with standard cable\"]         True                 True               True\n"
     ]
    }
   ],
   "source": [
    "# Identify outdoor columns\n",
    "outdoor_columns = [col for col in df.columns if col.startswith(\"outdoor_\")]\n",
    "\n",
    "# Get indices where outdoor features detected\n",
    "indices_with_outdoor = df[df[\"has_outdoor\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 2\n",
    "if test_index < len(indices_with_outdoor):\n",
    "    index_to_check = indices_with_outdoor[test_index]\n",
    "    true_outdoor_columns = [col for col in outdoor_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_outdoor\"] + true_outdoor_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected outdoor features ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_outdoor)} rows with has_outdoor == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b2773-14fe-4200-bad8-0b8d8992255f",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5aa60480-0265-4f95-a409-c8b42cee2779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_bath_bed_game_columns(df):\n",
    "    # Mapping of columns to target phrases\n",
    "    item_patterns = {\n",
    "        \"bath_item_shampoo\": \"shampoo\",\n",
    "        \"bath_item_body_soap\": \"body soap\",\n",
    "        \"bath_item_conditioner\": \"conditioner\",\n",
    "        \"kitchen_item_baking_sheet\": \"baking sheet\",\n",
    "        \"bed_item_bed_linens\": \"bed linens\",\n",
    "        \"game_item_games\": \"games\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_bath_bed_game_items\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "    for col in item_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # For detection efficiency\n",
    "    item_terms = list(item_patterns.values())\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        # Set general flag if any detected\n",
    "        if any(any(term in a for term in item_terms) for a in amenities_lower):\n",
    "            new_cols[\"has_bath_bed_game_items\"].at[idx] = True\n",
    "\n",
    "        # Set individual columns\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, term in item_patterns.items():\n",
    "                if term in amenity_lower:\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "04c1463b-6e81-4788-9f2b-86a31043bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bath_bed_game_items(df):\n",
    "    item_columns = [col for col in df.columns if col.startswith((\"bath_item_\", \"bed_item_\", \"game_item_\", \"kitchen_item_\"))]\n",
    "    item_counts = df[item_columns].sum().sort_values(ascending=False)\n",
    "    return item_counts.reset_index().rename(columns={\"index\": \"item_type\", 0: \"count\"})\n",
    "\n",
    "def count_bath_bed_game_with_and_without(df):\n",
    "    item_columns = [col for col in df.columns if col.startswith((\"bath_item_\", \"bed_item_\", \"game_item_\", \"kitchen_item_\"))]\n",
    "    has_type = df[item_columns].any(axis=1)\n",
    "    with_type = ((df[\"has_bath_bed_game_items\"]) & (has_type)).sum()\n",
    "    without_type = ((df[\"has_bath_bed_game_items\"]) & (~has_type)).sum()\n",
    "    return {\"with_type\": int(with_type), \"without_type\": int(without_type)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8cd18c4-0f81-44ee-926d-31251c615f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'with_type': 7174, 'without_type': 0}\n",
      "                   item_type  count\n",
      "0        bed_item_bed_linens   6464\n",
      "1          bath_item_shampoo   4383\n",
      "2        bath_item_body_soap   3640\n",
      "3  kitchen_item_baking_sheet   2826\n",
      "4      bath_item_conditioner   1103\n",
      "5            game_item_games    730\n"
     ]
    }
   ],
   "source": [
    "df = create_bath_bed_game_columns(df)\n",
    "\n",
    "# Get counts\n",
    "item_counts_df = count_bath_bed_game_items(df)\n",
    "item_summary = count_bath_bed_game_with_and_without(df)\n",
    "\n",
    "print(item_summary)\n",
    "print(item_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "696c59b0-0753-4579-a27c-00c8e857c0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 12 | Displaying amenities and detected bath/bed/game items ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              amenities  has_bath_bed_game_items  kitchen_item_baking_sheet  bed_item_bed_linens\n",
      "12  [\"Dishes and silverware\", \"Bed linens\", \"Cleaning available during stay\", \"Laundromat nearby\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"Dishwasher\", \"Cooking basics\", \"Smoking allowed\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Hot water kettle\", \"Shared patio or balcony\", \"Dedicated workspace\", \"Kitchen\", \"Single level home\", \"Iron\", \"Wine glasses\", \"Free street parking\", \"Washer\", \"Stove\", \"Hot water\", \"Baking sheet\", \"Room-darkening shades\", \"Host greets you\", \"Private entrance\", \"Oven\", \"Dining table\", \"TV with standard cable\", \"Microwave\"]                     True                       True                 True\n"
     ]
    }
   ],
   "source": [
    "# Identify item columns\n",
    "item_columns = [col for col in df.columns if col.startswith((\"bath_item_\", \"bed_item_\", \"game_item_\", \"kitchen_item_\"))]\n",
    "\n",
    "# Get indices where items detected\n",
    "indices_with_items = df[df[\"has_bath_bed_game_items\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "if test_index < len(indices_with_items):\n",
    "    index_to_check = indices_with_items[test_index]\n",
    "    true_item_columns = [col for col in item_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\", \"has_bath_bed_game_items\"] + true_item_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "    \n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected bath/bed/game items ===\")\n",
    "    print(df_check.to_string(max_colwidth=2000))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_items)} rows with has_bath_bed_game_items == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ef746-dfea-4a18-a3e9-38698bb3d73d",
   "metadata": {},
   "source": [
    "### WIFI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af4fea43-ca30-4c79-9d8f-26e7ebae46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_wifi_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_wifi\": pd.Series(False, index=df.index),\n",
    "        \"wifi_speed_mbps\": pd.Series(None, index=df.index, dtype=float)\n",
    "    }\n",
    "\n",
    "    # Loosened detection\n",
    "    wifi_terms_pattern = re.compile(\n",
    "        r\"(wifi|wi-fi|Ethernet|wireless internet)\"\n",
    "    )\n",
    "\n",
    "    # Improved speed extraction pattern:\n",
    "    wifi_speed_pattern = re.compile(\n",
    "        r\"(?:wifi.*?(?:–|-)\\s*)?(\\d{1,4}(?:[.,]\\d+)?)\\s*(?:mbps|mb/s|mps)\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        found_wifi = False\n",
    "        speeds = []\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            if wifi_terms_pattern.search(amenity):\n",
    "                found_wifi = True\n",
    "\n",
    "                match = wifi_speed_pattern.search(amenity)\n",
    "                if match:\n",
    "                    speed_str = match.group(1).replace(\",\", \".\")\n",
    "                    try:\n",
    "                        speed_value = float(speed_str)\n",
    "                        speeds.append(speed_value)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "        if found_wifi:\n",
    "            new_cols[\"has_wifi\"].at[idx] = True\n",
    "            if speeds:\n",
    "                new_cols[\"wifi_speed_mbps\"].at[idx] = max(speeds)\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e3ce2fc-9070-490f-9af7-4bab4cbe870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_wifi_summary(df):\n",
    "    has_wifi = df[\"has_wifi\"] == True\n",
    "    has_speed = df[\"wifi_speed_mbps\"].notna()\n",
    "\n",
    "    with_speed = (has_wifi & has_speed).sum()\n",
    "    without_speed = (has_wifi & ~has_speed).sum()\n",
    "    total_wifi = has_wifi.sum()\n",
    "\n",
    "    return {\n",
    "        \"total_wifi\": int(total_wifi),\n",
    "        \"with_speed\": int(with_speed),\n",
    "        \"without_speed\": int(without_speed)\n",
    "    }\n",
    "\n",
    "def wifi_speed_distribution(df, bins=None):\n",
    "    wifi_speeds = df.loc[df[\"wifi_speed_mbps\"].notna(), \"wifi_speed_mbps\"]\n",
    "    if bins:\n",
    "        return pd.cut(wifi_speeds, bins=bins).value_counts().sort_index()\n",
    "    else:\n",
    "        return wifi_speeds.value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e5b5a28-1ad6-4849-8f64-b124e8873f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_wifi': 8659, 'with_speed': 665, 'without_speed': 7994}\n",
      "    has_wifi  wifi_speed_mbps\n",
      "0       True              NaN\n",
      "1       True              NaN\n",
      "2       True              NaN\n",
      "3       True              NaN\n",
      "4       True              NaN\n",
      "5      False              NaN\n",
      "7       True              NaN\n",
      "9       True              NaN\n",
      "10      True              NaN\n",
      "11      True              NaN\n"
     ]
    }
   ],
   "source": [
    "df = create_wifi_columns(df)\n",
    "\n",
    "# Count summary\n",
    "wifi_summary = count_wifi_summary(df)\n",
    "print(wifi_summary)\n",
    "\n",
    "# Optional: Display raw speeds for review\n",
    "print(df[[\"has_wifi\", \"wifi_speed_mbps\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2dfa3df5-6034-4b40-8e6e-3b1d0c12d50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 2487 | Displaying amenities and detected WiFi info ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            amenities  has_wifi  wifi_speed_mbps\n",
      "2487  [\"Bathtub\", \"Drying rack for clothing\", \"Portable fans\", \"Shower gel\", \"Dishes and silverware\", \"City skyline view\", \"Bed linens\", \"I+m organic Berlin shampoo\", \"Laundromat nearby\", \"Long term stays allowed\", \"32 inch HDTV with standard cable\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Whirlpool induction stove\", \"High chair\", \"Coffee\", \"Dishwasher\", \"Cleaning products\", \"Freezer\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Blender\", \"Outdoor playground\", \"Hair dryer\", \"Extra pillows and blankets\", \"Carbon monoxide alarm\", \"Central heating\", \"Hot water kettle\", \"Elevator\", \"Dedicated workspace\", \"Kitchen\", \"Pack \\u2019n play/Travel crib\", \"Iron\", \"Fast wifi \\u2013 211 Mbps\", \"Baby bath\", \"Wine glasses\", \"Free street parking\", \"I+m organic Berlin body soap\", \"Clothing storage: wardrobe\", \"Hot water\", \"Smoke alarm\", \"Room-darkening shades\", \"Baking sheet\", \"Free parking on premises\", \"Host greets you\", \"Crib\", \"Oven\", \"Toaster\", \"Courtyard view\", \"Dining table\", \"Free washer \\u2013 In unit\", \"Microwave\"]      True            211.0\n"
     ]
    }
   ],
   "source": [
    "# Get indices where WiFi detected\n",
    "indices_with_wifi = df[df[\"wifi_speed_mbps\"].notna()].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 90\n",
    "if test_index < len(indices_with_wifi):\n",
    "    index_to_check = indices_with_wifi[test_index]\n",
    "    columns_to_display = [\"amenities\", \"has_wifi\", \"wifi_speed_mbps\"]\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected WiFi info ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_wifi)} rows with has_wifi == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896111c8-f58b-41ac-8a1e-bf08231dc75e",
   "metadata": {},
   "source": [
    "### Backyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa51abba-0dbc-432d-bcaf-1582487f89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_backyard_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_backyard\": pd.Series(False, index=df.index),\n",
    "        \"backyard_shared\": pd.Series(False, index=df.index),\n",
    "        \"backyard_fully_fenced\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    # Detection patterns\n",
    "    backyard_pattern = re.compile(r\"\\bbackyard\\b\")\n",
    "    shared_pattern = re.compile(r\"\\b(shared backyard|backyard.*shared)\\b\")\n",
    "    fenced_pattern = re.compile(r\"\\b(backyard.*fully fenced|fully fenced backyard)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        found_backyard = False\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            if backyard_pattern.search(amenity):\n",
    "                found_backyard = True\n",
    "\n",
    "                if shared_pattern.search(amenity):\n",
    "                    new_cols[\"backyard_shared\"].at[idx] = True\n",
    "\n",
    "                if fenced_pattern.search(amenity):\n",
    "                    new_cols[\"backyard_fully_fenced\"].at[idx] = True\n",
    "\n",
    "        if found_backyard:\n",
    "            new_cols[\"has_backyard\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28499118-aaef-41b0-ba40-0186ef975bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_backyard_features(df):\n",
    "    backyard_columns = [\"has_backyard\", \"backyard_shared\", \"backyard_fully_fenced\"]\n",
    "    backyard_counts = df[backyard_columns].sum().sort_values(ascending=False)\n",
    "    return backyard_counts.reset_index().rename(columns={\"index\": \"backyard_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6af2b4f-e890-4f3c-886c-03c220316626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        backyard_feature  count\n",
      "0           has_backyard   2100\n",
      "1  backyard_fully_fenced   1066\n",
      "2        backyard_shared    918\n"
     ]
    }
   ],
   "source": [
    "df = create_backyard_columns(df)\n",
    "\n",
    "# Display counts\n",
    "backyard_counts_df = count_backyard_features(df)\n",
    "print(backyard_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3651f746-67a3-4acb-a3f0-0c9968836c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 11 | Displaying amenities and detected backyard features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               amenities  has_backyard  backyard_fully_fenced\n",
      "11  [\"Bathtub\", \"Drying rack for clothing\", \"Dishes and silverware\", \"Garden view\", \"Bed linens\", \"Outdoor dining area\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"Ceiling fan\", \"Electric stove\", \"Private backyard \\u2013 Fully fenced\", \"Cooking basics\", \"Coffee maker: pour-over coffee\", \"Extra pillows and blankets\", \"Heating\", \"Hot water kettle\", \"Dedicated workspace\", \"Kitchen\", \"Outdoor furniture\", \"Wine glasses\", \"Free street parking\", \"Free washer \\u2013 In building\", \"Smoke alarm\", \"Hot water\", \"Room-darkening shades\", \"Baking sheet\", \"Oven\", \"Dining table\", \"Private patio or balcony\", \"TV with standard cable\"]          True                   True\n"
     ]
    }
   ],
   "source": [
    "# Identify backyard columns\n",
    "backyard_columns = [\"has_backyard\", \"backyard_shared\", \"backyard_fully_fenced\"]\n",
    "\n",
    "# Get indices where backyard features detected\n",
    "indices_with_backyard = df[df[\"has_backyard\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 2\n",
    "if test_index < len(indices_with_backyard):\n",
    "    index_to_check = indices_with_backyard[test_index]\n",
    "    true_backyard_columns = [col for col in backyard_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_backyard_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected backyard features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_backyard)} rows with has_backyard == True; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2c7d4-57bc-450e-b2ba-447b8cd41e65",
   "metadata": {},
   "source": [
    "### Balcony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a421d2e-2a05-47f6-85c1-3e3ca9ece3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_balcony_columns(df):\n",
    "    # Initialize column\n",
    "    new_cols = {\n",
    "        \"has_balcony\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    # Patterns for \"balcony\", \"balkon\", \"patio\"\n",
    "    balcony_pattern = re.compile(\n",
    "        r\"\\b(balcony|balkon|patio)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            if balcony_pattern.search(amenity):\n",
    "                new_cols[\"has_balcony\"].at[idx] = True\n",
    "                break  # no need to check further for this row\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2159aa4c-479b-4eea-8128-10cee1d59f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_balcony(df):\n",
    "    count = df[\"has_balcony\"].sum()\n",
    "    return {\"total_with_balcony\": int(count)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8a1ef3d-591c-43cc-a33d-217d6615daeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_with_balcony': 2987}\n",
      "                                            amenities  has_balcony\n",
      "0   [\"Bathtub\", \"Dishes and silverware\", \"Bed line...         True\n",
      "1   [\"Bathtub\", \"Dryer\", \"Dishes and silverware\", ...        False\n",
      "2   [\"Heating\", \"Host greets you\", \"Smoke alarm\", ...        False\n",
      "3   [\"Heating\", \"Room-darkening shades\", \"Children...        False\n",
      "4   [\"Dishes and silverware\", \"Luggage dropoff all...        False\n",
      "5   [\"Bathtub\", \"Dryer\", \"Drying rack for clothing...        False\n",
      "7   [\"Bathtub\", \"Safe\", \"Portable fans\", \"Dishes a...        False\n",
      "9   [\"Heating\", \"Host greets you\", \"Smoke alarm\", ...        False\n",
      "10  [\"Dryer\", \"Dishes and silverware\", \"Refrigerat...        False\n",
      "11  [\"Bathtub\", \"Drying rack for clothing\", \"Dishe...         True\n"
     ]
    }
   ],
   "source": [
    "df = create_balcony_columns(df)\n",
    "\n",
    "# Count\n",
    "balcony_summary = count_balcony(df)\n",
    "print(balcony_summary)\n",
    "\n",
    "# Quick QA\n",
    "print(df[[\"amenities\", \"has_balcony\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d829481-9dd1-460b-8a0c-d9f00f677768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 0 | Displaying amenities and detected balcony ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           amenities  has_balcony\n",
      "0  [\"Bathtub\", \"Dishes and silverware\", \"Bed linens\", \"Private hot tub\", \"Long term stays allowed\", \"Outdoor dining area\", \"Books and reading material\", \"Hangers\", \"TV\", \"Wifi\", \"High chair\", \"Refrigerator\", \"Coffee\", \"Children\\u2019s dinnerware\", \"Cleaning products\", \"Freezer\", \"Cooking basics\", \"Fire extinguisher\", \"First aid kit\", \"Essentials\", \"Clothing storage\", \"Coffee maker\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Carbon monoxide alarm\", \"Hot water kettle\", \"Kitchen\", \"Outdoor furniture\", \"Iron\", \"Wine glasses\", \"Washer\", \"Stove\", \"Hot water\", \"Smoke alarm\", \"Baking sheet\", \"Host greets you\", \"Crib\", \"Board games\", \"Ethernet connection\", \"Oven\", \"Toaster\", \"Dining table\", \"Patio or balcony\"]         True\n"
     ]
    }
   ],
   "source": [
    "# Get indices with balconies\n",
    "indices_with_balcony = df[df[\"has_balcony\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 0\n",
    "if test_index < len(indices_with_balcony):\n",
    "    index_to_check = indices_with_balcony[test_index]\n",
    "    columns_to_display = [\"amenities\", \"has_balcony\"]\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected balcony ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_balcony)} rows with has_balcony == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41273eaf-48d4-479d-8a19-2bf6b7e46ddc",
   "metadata": {},
   "source": [
    "### Heating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64fc7d4d-60a8-408a-acb5-f2e212794025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_heating_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_heating\": pd.Series(False, index=df.index),\n",
    "        \"has_central_heating\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    # Heating detection patterns\n",
    "    heating_pattern = re.compile(r\"\\b(heating|heater|radiator|heat)\\b\")\n",
    "    central_heating_pattern = re.compile(r\"\\b(central heating|zentralheizung)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Check for central heating\n",
    "            if central_heating_pattern.search(amenity):\n",
    "                new_cols[\"has_central_heating\"].at[idx] = True\n",
    "\n",
    "            # Check for any heating mention\n",
    "            if heating_pattern.search(amenity):\n",
    "                new_cols[\"has_heating\"].at[idx] = True\n",
    "\n",
    "            # If central heating detected, also ensure has_heating is True\n",
    "            if new_cols[\"has_central_heating\"].at[idx]:\n",
    "                new_cols[\"has_heating\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ae74b89f-6b87-47df-88b9-e095a96b282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_heating_features(df):\n",
    "    heating_columns = [\"has_heating\", \"has_central_heating\"]\n",
    "    heating_counts = df[heating_columns].sum().sort_values(ascending=False)\n",
    "    return heating_counts.reset_index().rename(columns={\"index\": \"heating_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9816f202-c574-4e2f-881a-eb7f4042449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       heating_feature  count\n",
      "0          has_heating   7711\n",
      "1  has_central_heating   2487\n"
     ]
    }
   ],
   "source": [
    "df = create_heating_columns(df)\n",
    "\n",
    "# Display counts\n",
    "heating_counts_df = count_heating_features(df)\n",
    "print(heating_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4f0dcd2-6dfb-4d0e-8a0b-a15b394d5fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 9 | Displaying amenities and detected heating features ===\n",
      "                                                                                                                                                                                                      amenities  has_heating\n",
      "9  [\"Heating\", \"Host greets you\", \"Smoke alarm\", \"Coffee maker\", \"Dishes and silverware\", \"Kitchen\", \"Private entrance\", \"Ethernet connection\", \"Refrigerator\", \"TV\", \"Hangers\", \"Washer\", \"Wifi\", \"Hot water\"]         True\n"
     ]
    }
   ],
   "source": [
    "# Identify heating columns\n",
    "heating_columns = [\"has_heating\", \"has_central_heating\"]\n",
    "\n",
    "# Get indices where heating is detected\n",
    "indices_with_heating = df[df[\"has_heating\"] == True].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "if test_index < len(indices_with_heating):\n",
    "    index_to_check = indices_with_heating[test_index]\n",
    "    true_heating_columns = [col for col in heating_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_heating_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected heating features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_heating)} rows with has_heating == True; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b036452-5114-4af9-be67-592dc5418345",
   "metadata": {},
   "source": [
    "### Hottub and Bathtub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dad32b63-8451-4b79-9bcc-343657fe3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_hottub_bathtub_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_hottub\": pd.Series(False, index=df.index),\n",
    "        \"has_bathtub\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    # Patterns\n",
    "    hottub_pattern = re.compile(r\"\\b(hot tub|jacuzzi|spa)\\b\")\n",
    "    bathtub_pattern = re.compile(r\"\\b(bathtub|badewanne)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Check for hot tub\n",
    "            if hottub_pattern.search(amenity):\n",
    "                new_cols[\"has_hottub\"].at[idx] = True\n",
    "\n",
    "            # Check for bathtub\n",
    "            if bathtub_pattern.search(amenity):\n",
    "                new_cols[\"has_bathtub\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ccd5a42-917a-4a39-812e-2afcb91bd1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_hottub_bathtub(df):\n",
    "    columns = [\"has_hottub\", \"has_bathtub\"]\n",
    "    counts = df[columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"feature\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d75c083f-f1f7-4ab3-8513-c387827254d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       feature  count\n",
      "0  has_bathtub   2692\n",
      "1   has_hottub    135\n"
     ]
    }
   ],
   "source": [
    "df = create_hottub_bathtub_columns(df)\n",
    "\n",
    "# Get counts\n",
    "ht_bt_counts_df = count_hottub_bathtub(df)\n",
    "print(ht_bt_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f76825a-2d35-4b78-b496-0849b74928ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 910 | Displaying amenities and detected hot tub / bathtub features ===\n",
      "                                                                                                                            amenities  has_hottub\n",
      "910  [\"Heating\", \"Dryer\", \"Elevator\", \"Kitchen\", \"Pets allowed\", \"Wifi\", \"Essentials\", \"Hot tub\", \"Washer\", \"TV with standard cable\"]        True\n"
     ]
    }
   ],
   "source": [
    "# Identify relevant columns\n",
    "columns = [\"has_hottub\", \"has_bathtub\"]\n",
    "\n",
    "# Get indices where hot tub or bathtub detected\n",
    "indices_with_features = df[(df[\"has_hottub\"] == True) ].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "if test_index < len(indices_with_features):\n",
    "    index_to_check = indices_with_features[test_index]\n",
    "    true_columns = [col for col in columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected hot tub / bathtub features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_features)} rows with hot tub or bathtub detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07451f-633b-42c9-b83a-8d042b6f5abc",
   "metadata": {},
   "source": [
    "### Washer and dryer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "abdd888c-6be9-4bad-abfa-9412d1151d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_washer_dryer_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"has_washer\": pd.Series(False, index=df.index),\n",
    "        \"washer_paid\": pd.Series(False, index=df.index),\n",
    "        \"washer_in_building\": pd.Series(False, index=df.index),\n",
    "        \"has_dryer\": pd.Series(False, index=df.index),\n",
    "        \"dryer_paid\": pd.Series(False, index=df.index),\n",
    "        \"dryer_in_building\": pd.Series(False, index=df.index),\n",
    "    }\n",
    "\n",
    "    # Patterns\n",
    "    washer_pattern = re.compile(r\"\\b(washer|washing machine)\\b\")\n",
    "    dryer_pattern = re.compile(r\"\\b(dryer|tumble dryer)\\b\")\n",
    "    paid_pattern = re.compile(r\"\\b(paid|coin operated|pay per use)\\b\")\n",
    "    in_building_pattern = re.compile(r\"\\b(in building|on premises)\\b\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Washer detection\n",
    "            if washer_pattern.search(amenity):\n",
    "                new_cols[\"has_washer\"].at[idx] = True\n",
    "                if paid_pattern.search(amenity):\n",
    "                    new_cols[\"washer_paid\"].at[idx] = True\n",
    "                if in_building_pattern.search(amenity):\n",
    "                    new_cols[\"washer_in_building\"].at[idx] = True\n",
    "\n",
    "            # Dryer detection\n",
    "            if dryer_pattern.search(amenity):\n",
    "                new_cols[\"has_dryer\"].at[idx] = True\n",
    "                if paid_pattern.search(amenity):\n",
    "                    new_cols[\"dryer_paid\"].at[idx] = True\n",
    "                if in_building_pattern.search(amenity):\n",
    "                    new_cols[\"dryer_in_building\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f23c780-970d-499d-8a62-458c46bd2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_washer_dryer_features(df):\n",
    "    columns = [\n",
    "        \"has_washer\", \"washer_paid\", \"washer_in_building\",\n",
    "        \"has_dryer\", \"dryer_paid\", \"dryer_in_building\"\n",
    "    ]\n",
    "    counts = df[columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"feature\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "758133cd-b480-41c5-aca6-c861561f56cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              feature  count\n",
      "0           has_dryer   7075\n",
      "1          has_washer   6730\n",
      "2  washer_in_building    892\n",
      "3   dryer_in_building    583\n",
      "4         washer_paid    441\n",
      "5          dryer_paid    275\n"
     ]
    }
   ],
   "source": [
    "df = create_washer_dryer_columns(df)\n",
    "\n",
    "# Get counts\n",
    "washer_dryer_counts_df = count_washer_dryer_features(df)\n",
    "print(washer_dryer_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9880f510-f1fd-4fd3-bc0c-be74668992e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 22 | Displaying amenities and detected washer/dryer features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            amenities  has_washer\n",
      "22  [\"Bathtub\", \"Canal view\", \"Drying rack for clothing\", \"Dishes and silverware\", \"Bed linens\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Dishwasher\", \"Cleaning products\", \"49 inch HDTV with Amazon Prime Video, Disney+, Netflix\", \"Freezer\", \"Bose SoundLink Mini II Bluetooth sound system\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Blender\", \"Heating\", \"Carbon monoxide alarm\", \"Hot water kettle\", \"Waterfront\", \"Dedicated workspace\", \"Kitchen\", \"Iron\", \"Wine glasses\", \"Washer\", \"Fast wifi \\u2013 104 Mbps\", \"Stove\", \"Smoke alarm\", \"Body soap\", \"Hot water\", \"Baking sheet\", \"Host greets you\", \"Oven\", \"Toaster\", \"Dining table\", \"Private patio or balcony\", \"Microwave\"]        True\n"
     ]
    }
   ],
   "source": [
    "# Identify columns\n",
    "columns = [\n",
    "    \"has_washer\", \"washer_paid\", \"washer_in_building\",\n",
    "    \"has_dryer\", \"dryer_paid\", \"dryer_in_building\"\n",
    "]\n",
    "\n",
    "# Get indices where washer or dryer detected\n",
    "indices_with_features = df[\n",
    "    (df[\"has_washer\"] == True) | (df[\"has_dryer\"] == True)\n",
    "].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 17\n",
    "if test_index < len(indices_with_features):\n",
    "    index_to_check = indices_with_features[test_index]\n",
    "    true_columns = [col for col in columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected washer/dryer features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_features)} rows with washer or dryer detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ffb6c3-412a-4e79-87eb-a02e043a207b",
   "metadata": {},
   "source": [
    "### Hoesekeeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ca558f4-9728-4d6c-8e49-6dc88c2b1117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_housekeeping_columns(df):\n",
    "    # Initialize columns\n",
    "    new_cols = {\n",
    "        \"housekeeping_included\": pd.Series(False, index=df.index),\n",
    "        \"housekeeping_available_at_cost\": pd.Series(False, index=df.index)\n",
    "    }\n",
    "\n",
    "    # Patterns\n",
    "    included_pattern = re.compile(\n",
    "        r\"\\b(housekeeping|cleaning|maid service|room cleaning).*(included|provided|free)\\b\"\n",
    "    )\n",
    "    available_at_cost_pattern = re.compile(\n",
    "        r\"\\b(housekeeping|cleaning|maid service|room cleaning).*(available|optional|on request).*(fee|cost|extra|additional)\\b\"\n",
    "    )\n",
    "\n",
    "    # Also handle shorter phrases like \"Cleaning available for a fee\"\n",
    "    fallback_available_pattern = re.compile(\n",
    "        r\"\\b(cleaning|housekeeping).*(fee|cost|extra|additional)\\b\"\n",
    "    )\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity in amenities_lower:\n",
    "            # Check for housekeeping included\n",
    "            if included_pattern.search(amenity):\n",
    "                new_cols[\"housekeeping_included\"].at[idx] = True\n",
    "\n",
    "            # Check for housekeeping available at cost\n",
    "            if available_at_cost_pattern.search(amenity) or fallback_available_pattern.search(amenity):\n",
    "                new_cols[\"housekeeping_available_at_cost\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2c4413d8-133c-4327-963a-d3cfbbc21d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_housekeeping_features(df):\n",
    "    housekeeping_columns = [\"housekeeping_included\", \"housekeeping_available_at_cost\"]\n",
    "    counts = df[housekeeping_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"housekeeping_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "35811ec2-bd48-4bb6-a5cb-93588b375cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             housekeeping_feature  count\n",
      "0  housekeeping_available_at_cost    325\n",
      "1           housekeeping_included     29\n"
     ]
    }
   ],
   "source": [
    "df = create_housekeeping_columns(df)\n",
    "\n",
    "# Get counts\n",
    "housekeeping_counts_df = count_housekeeping_features(df)\n",
    "print(housekeeping_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "08203f8b-e2e6-4b46-9f3b-3ea7698b72b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 553 | Displaying amenities and detected housekeeping features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         amenities  housekeeping_available_at_cost\n",
      "553  [\"Bathtub\", \"Dryer\", \"Shower gel\", \"Dishes and silverware\", \"City skyline view\", \"Bed linens\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"Shampoo\", \"Dishwasher\", \"Housekeeping - available at extra cost\", \"Cleaning products\", \"Freezer\", \"Conditioner\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Elevator\", \"Dedicated workspace\", \"Kitchen\", \"Iron\", \"Wine glasses\", \"Washer\", \"Stove\", \"Clothing storage: wardrobe\", \"Hot water\", \"Baking sheet\", \"Room-darkening shades\", \"Oven\", \"Toaster\", \"Dining table\", \"Private patio or balcony\", \"TV with standard cable\", \"Microwave\"]                            True\n"
     ]
    }
   ],
   "source": [
    "# Identify columns\n",
    "housekeeping_columns = [\"housekeeping_included\", \"housekeeping_available_at_cost\"]\n",
    "\n",
    "# Get indices where housekeeping detected\n",
    "indices_with_housekeeping = df[\n",
    "    (df[\"housekeeping_included\"] == True) | (df[\"housekeeping_available_at_cost\"] == True)\n",
    "].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "if test_index < len(indices_with_housekeeping):\n",
    "    index_to_check = indices_with_housekeeping[test_index]\n",
    "    true_columns = [col for col in housekeeping_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected housekeeping features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_housekeeping)} rows with housekeeping detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6304e99e-3f36-44fc-a638-9b24a30271a5",
   "metadata": {},
   "source": [
    "### Baby and children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "682bb409-0783-4c74-b3a3-6ab44d8b4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_baby_columns(df):\n",
    "    # Mapping of columns to detection phrases\n",
    "    baby_patterns = {\n",
    "        \"baby_bath\": r\"\\bbaby bath\\b\",\n",
    "        \"baby_monitor\": r\"\\bbaby monitor\\b\",\n",
    "        \"baby_safety\": r\"\\b(baby safety|child safety|baby gate|safety gate|cabinet locks)\\b\",\n",
    "        \"children_books_and_toys\": r\"\\b(children's books and toys|children books and toys|kids books and toys|toys|books for kids|books and toys)\\b\",\n",
    "        \"crib\": r\"\\b(crib|baby bed|cot)\\b\",\n",
    "        \"high_chair\": r\"\\b(high chair|baby chair)\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {}\n",
    "    for col in baby_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, pattern in baby_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7c124b3a-d984-43e9-a375-0ef24f452ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_baby_features(df):\n",
    "    baby_columns = [\n",
    "        \"baby_bath\",\n",
    "        \"baby_monitor\",\n",
    "        \"baby_safety\",\n",
    "        \"children_books_and_toys\",\n",
    "        \"crib\",\n",
    "        \"high_chair\"\n",
    "    ]\n",
    "    counts = df[baby_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"baby_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "141286e6-99e3-4907-8f2e-52f1dee93251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              baby_feature  count\n",
      "0                     crib   2442\n",
      "1               high_chair   1721\n",
      "2  children_books_and_toys    802\n",
      "3                baby_bath    355\n",
      "4             baby_monitor     76\n",
      "5              baby_safety     58\n"
     ]
    }
   ],
   "source": [
    "df = create_baby_columns(df)\n",
    "\n",
    "# Get counts\n",
    "baby_counts_df = count_baby_features(df)\n",
    "print(baby_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f3558880-088e-4acc-b76e-89a31bc02097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 16 | Displaying amenities and detected baby features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     amenities  children_books_and_toys  crib  high_chair\n",
      "16  [\"Dryer\", \"Dishes and silverware\", \"Bed linens\", \"Luggage dropoff allowed\", \"Long term stays allowed\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"High chair\", \"Dishwasher\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Extra pillows and blankets\", \"Heating\", \"Dedicated workspace\", \"Kitchen\", \"Pack \\u2019n play/Travel crib\", \"Iron\", \"Paid parking off premises\", \"Washer\", \"Stove\", \"Hot water\", \"Host greets you\", \"Children\\u2019s books and toys\", \"Crib\", \"Ethernet connection\", \"Oven\", \"TV with standard cable\"]                     True  True        True\n"
     ]
    }
   ],
   "source": [
    "# Identify baby columns\n",
    "baby_columns = [\n",
    "    \"baby_bath\",\n",
    "    \"baby_monitor\",\n",
    "    \"baby_safety\",\n",
    "    \"children_books_and_toys\",\n",
    "    \"crib\",\n",
    "    \"high_chair\"\n",
    "]\n",
    "\n",
    "# Get indices where any baby feature is detected\n",
    "indices_with_baby = df[df[baby_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "if test_index < len(indices_with_baby):\n",
    "    index_to_check = indices_with_baby[test_index]\n",
    "    true_columns = [col for col in baby_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected baby features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_baby)} rows with baby features detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1f63c-d96f-4299-9637-555303e682e3",
   "metadata": {},
   "source": [
    "### Variuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99e6dcf5-4425-46af-a5f3-58e9c6e72937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_miscellaneous_columns(df):\n",
    "    # Mapping of column names to detection patterns\n",
    "    misc_patterns = {\n",
    "        \"luggage_dropoff_allowed\": r\"\\bluggage dropoff allowed\\b\",\n",
    "        \"long_term_stays_allowed\": r\"\\blong term stays allowed\\b\",\n",
    "        \"air_conditioning\": r\"\\bair conditioning\\b\",\n",
    "        \"pets_allowed\": r\"\\b(pets allowed|pet friendly)\\b\",\n",
    "        \"ping_pong_table\": r\"\\bping pong table\\b\",\n",
    "        \"host_greets_you\": r\"\\bhost greets you\\b\",\n",
    "        \"private_entrance\": r\"\\bprivate entrance\\b\",\n",
    "        \"shared_entrance\": r\"\\bshared entrance\\b\",\n",
    "        \"workspace\": r\"\\b(workspace|dedicated workspace|desk|working space|work space)\\b\"\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {}\n",
    "    for col in misc_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, pattern in misc_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c12ed629-d685-41b3-adfa-bf67939024c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_miscellaneous_features(df):\n",
    "    misc_columns = [\n",
    "        \"luggage_dropoff_allowed\",\n",
    "        \"long_term_stays_allowed\",\n",
    "        \"air_conditioning\",\n",
    "        \"pets_allowed\",\n",
    "        \"ping_pong_table\",\n",
    "        \"host_greets_you\",\n",
    "        \"private_entrance\",\n",
    "        \"shared_entrance\",\n",
    "        \"workspace\"\n",
    "    ]\n",
    "    counts = df[misc_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"misc_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aae288b5-97ea-4001-b189-0bf32e0a1a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              misc_feature  count\n",
      "0                workspace   5344\n",
      "1  long_term_stays_allowed   4156\n",
      "2  luggage_dropoff_allowed   2531\n",
      "3         private_entrance   2514\n",
      "4          host_greets_you   2128\n",
      "5             pets_allowed   2066\n",
      "6         air_conditioning    631\n",
      "7          ping_pong_table    144\n",
      "8          shared_entrance      0\n"
     ]
    }
   ],
   "source": [
    "df = create_miscellaneous_columns(df)\n",
    "\n",
    "# Display counts\n",
    "misc_counts_df = count_miscellaneous_features(df)\n",
    "print(misc_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "24f4f488-c2db-413a-8c72-225a587c445b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 10 | Displaying amenities and detected miscellaneous features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        amenities  private_entrance  workspace\n",
      "10  [\"Dryer\", \"Dishes and silverware\", \"Refrigerator\", \"Hangers\", \"Wifi\", \"High chair\", \"Shampoo\", \"Dishwasher\", \"Cooking basics\", \"Essentials\", \"Coffee maker\", \"Hair dryer\", \"Smart lock\", \"Heating\", \"Elevator\", \"Self check-in\", \"Dedicated workspace\", \"Kitchen\", \"Pack \\u2019n play/Travel crib\", \"Iron\", \"Backyard\", \"Washer\", \"Smoke alarm\", \"Hot water\", \"Room-darkening shades\", \"Free parking on premises\", \"Crib\", \"Private entrance\", \"Oven\", \"TV with standard cable\", \"Microwave\"]              True       True\n"
     ]
    }
   ],
   "source": [
    "# Identify miscellaneous columns\n",
    "misc_columns = [\n",
    "    \"luggage_dropoff_allowed\",\n",
    "    \"long_term_stays_allowed\",\n",
    "    \"air_conditioning\",\n",
    "    \"pets_allowed\",\n",
    "    \"ping_pong_table\",\n",
    "    \"host_greets_you\",\n",
    "    \"private_entrance\",\n",
    "    \"shared_entrance\",\n",
    "    \"workspace\"\n",
    "]\n",
    "\n",
    "# Get indices where any miscellaneous feature is detected\n",
    "indices_with_misc = df[df[misc_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 7\n",
    "if test_index < len(indices_with_misc):\n",
    "    index_to_check = indices_with_misc[test_index]\n",
    "    true_columns = [col for col in misc_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected miscellaneous features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_misc)} rows with miscellaneous features detected; test_index {test_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8327f4-eef5-4b57-b8ad-3d34272de345",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8f31d7c2-35c2-4cbe-93d2-625269826c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_view_columns(df):\n",
    "    # Mapping columns to detection patterns\n",
    "    view_patterns = {\n",
    "        \"beach_view\": r\"\\bbeach view\\b\",\n",
    "        \"city_skyline_view\": r\"\\bcity skyline view\\b\",\n",
    "        \"desert_view\": r\"\\bdesert view\\b\",\n",
    "        \"garden_view\": r\"\\bgarden view\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {}\n",
    "    for col in view_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity_lower in amenities_lower:\n",
    "            for col_name, pattern in view_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "59769235-5968-42ba-817c-211fc3fa1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_view_features(df):\n",
    "    view_columns = [\"beach_view\", \"city_skyline_view\", \"desert_view\", \"garden_view\"]\n",
    "    counts = df[view_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"view_feature\", 0: \"count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "639c6551-eeb1-422b-8d9f-19a7ecd29c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        view_feature  count\n",
      "0        garden_view    557\n",
      "1  city_skyline_view    411\n",
      "2         beach_view      6\n",
      "3        desert_view      1\n"
     ]
    }
   ],
   "source": [
    "df = create_view_columns(df)\n",
    "\n",
    "# Display counts\n",
    "view_counts_df = count_view_features(df)\n",
    "print(view_counts_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d545fe-d00e-45b6-834e-0c1b0ade5cc8",
   "metadata": {},
   "source": [
    "### Gym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6a8a71ea-d902-4684-b71d-100e796c3551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def create_gym_columns(df):\n",
    "    # Mapping columns to detection patterns\n",
    "    gym_patterns = {\n",
    "        \"gym_private_in_building\": r\"\\bprivate gym in building\\b\",\n",
    "        \"gym_private_nearby\": r\"\\bprivate gym nearby\\b\",\n",
    "        \"gym_shared_in_building\": r\"\\bshared gym in building\\b\",\n",
    "        \"gym_shared_nearby\": r\"\\bshared gym nearby\\b\",\n",
    "        \"gym_private\": r\"\\bprivate gym\\b\",\n",
    "        \"gym_shared\": r\"\\bshared gym\\b\",\n",
    "    }\n",
    "\n",
    "    # Initialize columns\n",
    "    new_cols = {}\n",
    "    for col in gym_patterns.keys():\n",
    "        new_cols[col] = pd.Series(False, index=df.index)\n",
    "\n",
    "    # Optional general gym detection\n",
    "    new_cols[\"gym\"] = pd.Series(False, index=df.index)\n",
    "\n",
    "    for idx in df.index:\n",
    "        amenities = get_amenities_at_index(df, idx)\n",
    "        amenities_lower = [a.lower() for a in amenities]\n",
    "\n",
    "        for amenity_lower in amenities_lower:\n",
    "            # Mark specific private/shared patterns\n",
    "            for col_name, pattern in gym_patterns.items():\n",
    "                if re.search(pattern, amenity_lower):\n",
    "                    new_cols[col_name].at[idx] = True\n",
    "\n",
    "            # General gym detection\n",
    "            if \"gym\" in amenity_lower:\n",
    "                new_cols[\"gym\"].at[idx] = True\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame(new_cols)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e46f3e6f-511d-4a96-a399-353bc46d30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_gym_features(df):\n",
    "    gym_columns = [\n",
    "        \"gym\",\n",
    "        \"gym_private\",\n",
    "        \"gym_private_in_building\",\n",
    "        \"gym_private_nearby\",\n",
    "        \"gym_shared\",\n",
    "        \"gym_shared_in_building\",\n",
    "        \"gym_shared_nearby\"\n",
    "    ]\n",
    "    counts = df[gym_columns].sum().sort_values(ascending=False)\n",
    "    return counts.reset_index().rename(columns={\"index\": \"gym_feature\", 0: \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "281a94d4-1797-4b5d-aa11-9e608dd9c71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               gym_feature  count\n",
      "0                      gym    179\n",
      "1               gym_shared     87\n",
      "2   gym_shared_in_building     53\n",
      "3        gym_shared_nearby     32\n",
      "4              gym_private     25\n",
      "5  gym_private_in_building     22\n",
      "6       gym_private_nearby      1\n"
     ]
    }
   ],
   "source": [
    "df = create_gym_columns(df)\n",
    "\n",
    "# Display counts\n",
    "gym_counts_df = count_gym_features(df)\n",
    "print(gym_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e698751e-0de7-48ed-b8b8-6ed39565d35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Index: 1736 | Displaying amenities and detected gym features ===\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               amenities   gym  gym_private  gym_private_in_building\n",
      "1736  [\"Bathtub\", \"Drying rack for clothing\", \"Smeg gas stove\", \"Shower gel\", \"Dishes and silverware\", \"Garden view\", \"Bed linens\", \"Luggage dropoff allowed\", \"Indoor fireplace: wood-burning\", \"Outdoor dining area\", \"Private gym in building\", \"Books and reading material\", \"Hangers\", \"Refrigerator\", \"Long term stays allowed\", \"Housekeeping available Tuesday, Friday - available at extra cost\", \"Shampoo\", \"Dishwasher\", \"Cleaning products\", \"Hammock\", \"Cooking basics\", \"Fire extinguisher\", \"First aid kit\", \"Essentials\", \"Free dryer \\u2013 In building\", \"Extra pillows and blankets\", \"Hair dryer\", \"Heating\", \"Carbon monoxide alarm\", \"Hot water kettle\", \"Dedicated workspace\", \"Kitchen\", \"Outdoor furniture\", \"Iron\", \"BBQ grill\", \"Wine glasses\", \"Fast wifi \\u2013 106 Mbps\", \"Free washer \\u2013 In building\", \"Coffee maker: espresso machine\", \"Clothing storage: wardrobe\", \"Hot water\", \"Body soap\", \"Room-darkening shades\", \"Smoke alarm\", \"Baking sheet\", \"Shared backyard \\u2013 Not fully fenced\", \"Board games\", \"Sun loungers\", \"Ethernet connection\", \"65 inch HDTV with Amazon Prime Video, Netflix, premium cable, standard cable\", \"Oven\", \"Courtyard view\", \"Dining table\", \"Private patio or balcony\", \"Exercise equipment\"]  True         True                     True\n"
     ]
    }
   ],
   "source": [
    "# Identify gym columns\n",
    "gym_columns = [\n",
    "    \"gym\",\n",
    "    \"gym_private\",\n",
    "    \"gym_private_in_building\",\n",
    "    \"gym_private_nearby\",\n",
    "    \"gym_shared\",\n",
    "    \"gym_shared_in_building\",\n",
    "    \"gym_shared_nearby\"\n",
    "]\n",
    "\n",
    "# Get indices where any gym feature is detected\n",
    "indices_with_gym = df[df[gym_columns].any(axis=1)].index\n",
    "\n",
    "# Select test index\n",
    "test_index = 8\n",
    "if test_index < len(indices_with_gym):\n",
    "    index_to_check = indices_with_gym[test_index]\n",
    "    true_columns = [col for col in gym_columns if df.at[index_to_check, col] == True]\n",
    "    columns_to_display = [\"amenities\"] + true_columns\n",
    "    df_check = df.loc[[index_to_check], columns_to_display]\n",
    "\n",
    "    print(f\"\\n=== Index: {index_to_check} | Displaying amenities and detected gym features ===\")\n",
    "    print(df_check.to_string(max_colwidth=1500))\n",
    "else:\n",
    "    print(f\"Only {len(indices_with_gym)} rows with gym features detected; test_index {test_index} is out of range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "addf104f-78bb-432e-a5fc-932905512abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8898, 259)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5311fb3-170b-4f97-ae68-bb69a131c406",
   "metadata": {},
   "source": [
    "### Square meters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "caff7c82-8dfb-4423-9056-13c721d21692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract size in square meters\n",
    "def extract_square_meters(text):\n",
    "    if pd.isnull(text):\n",
    "        return None\n",
    "    match = re.search(r\"\\b(\\d{1,3})\\s?(m2|m²|sqm|square meter|qm|quadratmeter)\\b\", text.lower())\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Apply to both 'name' and 'description', preferring 'name' first if both are present\n",
    "def get_size_from_name_or_description(row):\n",
    "    name_size = extract_square_meters(row[\"name\"])\n",
    "    if name_size:\n",
    "        return name_size\n",
    "    return extract_square_meters(row[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d53e644-59f3-4f30-9143-1fa83762f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sqm\"] = df.apply(get_size_from_name_or_description, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cfd4b9ff-6075-4a3a-9a9e-c0088a9d5696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 name  \\\n",
      "25            Italian Design at Kudamm ,WiFi DSL free   \n",
      "28  Spacious Prenzlauer Berg Apartment in Quiet St...   \n",
      "44                Beautiful flat 95m² in Berlin Mitte   \n",
      "78                  Excl. Studio A Mitte/Hansaviertel   \n",
      "79                  Excl. Studio B Mitte/Hansaviertel   \n",
      "\n",
      "                                          description   sqm  \n",
      "25  This charming fully furnished ,46m2 flat is lo...  46.0  \n",
      "28  Our apt (90sqm / 1.000sqft) is in a 1893 histo...  90.0  \n",
      "44                                                NaN  95.0  \n",
      "78  Exclusive Studio A  35qm, quiet & central, SW-...  35.0  \n",
      "79  exclusive Studio B (one of two studio A/B w. s...  35.0  \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df[\"sqm\"].notna(), [\"name\", \"description\", \"sqm\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7cc319-ed5f-42a8-8f0e-5b6776b436e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce75b1ce-50ab-492b-b5c9-f66c6368bade",
   "metadata": {},
   "source": [
    "### Fill with name and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82ef8c41-d269-4810-b896-a85f2ae39a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def fill_features_from_name_and_description(df):\n",
    "    # Patterns for each column (EN + DE)\n",
    "    feature_patterns = {\n",
    "        \"has_backyard\": r\"\\b(backyard|garten|hof)\\b\",\n",
    "        \"backyard_shared\": r\"\\b(shared backyard|gemeinschaftsgarten)\\b\",\n",
    "        \"backyard_fully_fenced\": r\"\\b(fully fenced backyard|eingezäunter garten|komplett umzäunt)\\b\",\n",
    "        \"has_balcony\": r\"\\b(balcony|balkon)\\b\",\n",
    "        \"has_hottub\": r\"\\b(hot tub|whirlpool|jacuzzi)\\b\",\n",
    "        \"private_entrance\": r\"\\b(private entrance|eigener eingang)\\b\",\n",
    "        \"shared_entrance\": r\"\\b(shared entrance|geteilten eingang|geteilter eingang)\\b\",\n",
    "        \"workspace\": r\"\\b(workspace|arbeitsplatz|schreibtisch|arbeitsbereich)\\b\",\n",
    "        \"outdoor_pool_shared\": r\"\\b(shared outdoor pool|gemeinschaftspool)\\b\",\n",
    "        \"outdoor_pool_private\": r\"\\b(private outdoor pool|eigener pool|privatpool)\\b\",\n",
    "    }\n",
    "\n",
    "    for feature, pattern in feature_patterns.items():\n",
    "        regex = re.compile(pattern, flags=re.IGNORECASE)\n",
    "        df[feature] = df.apply(\n",
    "            lambda row: bool(regex.search(\n",
    "                f\"{str(row.get('name', ''))} {str(row.get('description', ''))}\"\n",
    "            )),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d29e982a-84f7-4a2c-b441-7d50be7f8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_features_from_name_and_description(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb8c42-5a76-42f6-bd54-2f7a1bb61024",
   "metadata": {},
   "source": [
    "### Transform given columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a234b2e-292a-4ba7-b4c6-68185804c40f",
   "metadata": {},
   "source": [
    "#### Distance to ubahn stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "95864c8d-854b-427c-9ebe-f8f0b73f7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Function to convert DMS to decimal degrees\n",
    "def dms_to_decimal(degrees, minutes, seconds, direction):\n",
    "    decimal = float(degrees) + float(minutes) / 60 + float(seconds) / 3600\n",
    "    if direction in ['S', 'W']:  # South and West should be negative\n",
    "        decimal = -decimal\n",
    "    return decimal\n",
    "\n",
    "# URL of the Wikipedia page\n",
    "url = 'https://de.wikipedia.org/wiki/Liste_der_Berliner_U-Bahnh%C3%B6fe'\n",
    "\n",
    "# Fetch the page content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Get the entire text of the page\n",
    "page_text = soup.get_text()\n",
    "\n",
    "# Define a regular expression pattern for coordinates\n",
    "coordinate_pattern = r'(\\d{1,3})°\\s(\\d{1,2})′\\s(\\d{1,2})″\\s([NS]),\\s(\\d{1,3})°\\s(\\d{1,2})′\\s(\\d{1,2})″\\s([EO])'\n",
    "\n",
    "# Find all matches in the page text\n",
    "coordinates = re.findall(coordinate_pattern, page_text)\n",
    "\n",
    "list_coordinates = []\n",
    "\n",
    "# Convert the found coordinates to decimal degrees and print them\n",
    "for coord in coordinates:\n",
    "    # Latitude\n",
    "    lat_deg, lat_min, lat_sec, lat_dir = coord[0], coord[1], coord[2], coord[3]\n",
    "    lat_decimal = dms_to_decimal(lat_deg, lat_min, lat_sec, lat_dir)\n",
    "    \n",
    "    # Longitude\n",
    "    lon_deg, lon_min, lon_sec, lon_dir = coord[4], coord[5], coord[6], coord[7]\n",
    "    \n",
    "    lon_decimal = dms_to_decimal(lon_deg, lon_min, lon_sec, lon_dir)\n",
    "    list_coordinates.append((lat_decimal,lon_decimal))\n",
    "    # Print the results\n",
    "    #print(f\"Latitude: {lat_decimal}, Longitude: {lon_decimal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1434f10b-45a6-42c8-a96f-63f4984df986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_distance_to_ubahn(row):\n",
    "    # Get the coordinates of the listing\n",
    "    listing_coords = (row['latitude'], row['longitude'])\n",
    "\n",
    "    \n",
    "    # Calculate the distance to each U-Bahn station\n",
    "    distances = [geodesic(listing_coords, ubahn).kilometers for ubahn in list_coordinates]\n",
    "    \n",
    "    # Return the minimum distance\n",
    "    return min(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "24d9b517-9b6f-411d-b3e1-c5263521567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a while\n",
    "df[\"distance_ubahn\"] = df.apply(minimum_distance_to_ubahn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d781c879-3fba-4219-984d-b0859cdf54fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        latitude  longitude  distance_ubahn\n",
      "4444   52.499110  13.428130        0.008082\n",
      "3339   52.516650  13.445160        0.011019\n",
      "6703   52.549290  13.416070        0.014005\n",
      "7961   52.491263  13.396210        0.015524\n",
      "11390  52.510430  13.415720        0.018605\n",
      "11201  52.505673  13.390466        0.018840\n",
      "8737   52.505673  13.390466        0.018840\n",
      "8738   52.505673  13.390466        0.018840\n",
      "3680   52.515980  13.454000        0.019859\n",
      "4124   52.499020  13.428290        0.022800\n",
      "34     52.525360  13.404880        0.023235\n",
      "10753  52.493796  13.309831        0.023528\n",
      "12177  52.537558  13.396317        0.024595\n",
      "11473  52.502700  13.325380        0.025247\n",
      "13624  52.492980  13.421580        0.026142\n",
      "7995   52.473090  13.314414        0.027162\n",
      "598    52.525970  13.343670        0.027448\n",
      "4773   52.473820  13.427840        0.027474\n",
      "2157   52.530870  13.382410        0.027517\n",
      "3899   52.515080  13.418440        0.027575\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"latitude\", \"longitude\", \"distance_ubahn\"]].sort_values(by=\"distance_ubahn\", ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1b48d-fd3b-4575-b7ba-995cbe75a7c4",
   "metadata": {},
   "source": [
    "#### Host lives in Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "021644f7-9dcb-4af3-83bd-078e08f0930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1         True\n",
       "2         True\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "13940    False\n",
       "13941    False\n",
       "13942     True\n",
       "13943    False\n",
       "13944     True\n",
       "Name: host_in_berlin, Length: 8898, dtype: bool"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"host_in_berlin\"] = df[\"host_location\"].astype(str).str.contains(\"berlin\", case=False, na=False)\n",
    "df[\"host_in_berlin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fedd3d2-7eec-44b9-b9ab-5d82d71f9847",
   "metadata": {},
   "source": [
    "#### Make host neighbourhood numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bfea705d-e4f3-4540-8c20-5de7803222a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_coords = {\n",
    "    \"Prenzlauer Berg\": (13.424, 52.538),\n",
    "    \"Kreuzberg\": (13.403, 52.499),\n",
    "    \"Neukölln\": (13.438, 52.480),\n",
    "    \"Charlottenburg\": (13.291, 52.505),\n",
    "    \"Friedrichshain\": (13.454, 52.515),\n",
    "    \"Mitte\": (13.400, 52.520),\n",
    "    \"Wedding\": (13.363, 52.552),\n",
    "    \"Schöneberg\": (13.356, 52.483),\n",
    "    \"Tiergarten\": (13.353, 52.516),\n",
    "    \"Wilmersdorf\": (13.308, 52.487),\n",
    "    \"Moabit\": (13.339, 52.530),\n",
    "    \"Tempelhof\": (13.385, 52.468),\n",
    "    \"Lichtenberg\": (13.499, 52.515),\n",
    "    \"Treptow\": (13.471, 52.480),\n",
    "    \"Steglitz\": (13.326, 52.456),\n",
    "    \"Marzahn\": (13.545, 52.545),\n",
    "    \"Pankow\": (13.401, 52.569),\n",
    "    \"Reinickendorf\": (13.334, 52.584),\n",
    "    \"Spandau\": (13.206, 52.535),\n",
    "}\n",
    "# Function to map neighbourhood to coordinates\n",
    "def get_neighbourhood_coords(neighbourhood):\n",
    "    if pd.isna(neighbourhood):\n",
    "        return pd.Series({\"longitude_neighbourhood\": None, \"latitude_neighbourhood\": None})\n",
    "    coords = neighbourhood_coords.get(neighbourhood.strip())\n",
    "    if coords:\n",
    "        lon, lat = coords\n",
    "        return pd.Series({\"longitude_neighbourhood\": lon, \"latitude_neighbourhood\": lat})\n",
    "    else:\n",
    "        return pd.Series({\"longitude_neighbourhood\": None, \"latitude_neighbourhood\": None})\n",
    "\n",
    "# Apply to df\n",
    "df[[\"longitude_neighbourhood\", \"latitude_neighbourhood\"]] = df[\"host_neighbourhood\"].apply(get_neighbourhood_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "074c2d66-ff0e-4ed8-b8cc-567d93a922f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   host_neighbourhood  longitude_neighbourhood  latitude_neighbourhood\n",
      "0     Prenzlauer Berg                   13.424                  52.538\n",
      "1     Prenzlauer Berg                   13.424                  52.538\n",
      "2     Prenzlauer Berg                   13.424                  52.538\n",
      "3           Kreuzberg                   13.403                  52.499\n",
      "4          Copacabana                      NaN                     NaN\n",
      "5           Kreuzberg                   13.403                  52.499\n",
      "7               Mitte                   13.400                  52.520\n",
      "9     Prenzlauer Berg                   13.424                  52.538\n",
      "10    Prenzlauer Berg                   13.424                  52.538\n",
      "11        Wilmersdorf                   13.308                  52.487\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"host_neighbourhood\", \"longitude_neighbourhood\", \"latitude_neighbourhood\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9170b311-9564-4ffe-a363-bbd2c5499d2c",
   "metadata": {},
   "source": [
    "#### Make host response time numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "971e43ca-c481-4b29-a8e2-b719da2cf679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    host_response_time  host_response_time_numeric\n",
      "0         within a day                        24.0\n",
      "1   a few days or more                        96.0\n",
      "2   within a few hours                         3.0\n",
      "4       within an hour                         1.0\n",
      "7   within a few hours                         3.0\n",
      "9   within a few hours                         3.0\n",
      "10      within an hour                         1.0\n",
      "11  within a few hours                         3.0\n",
      "16      within an hour                         1.0\n",
      "17      within an hour                         1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define mapping dictionary\n",
    "response_time_mapping = {\n",
    "    \"within an hour\": 1,\n",
    "    \"within a few hours\": 3,\n",
    "    \"within a day\": 24,\n",
    "    \"within a few days\": 72,\n",
    "    \"a few days or more\": 96\n",
    "}\n",
    "\n",
    "# Clean, lower, and map\n",
    "df[\"host_response_time_numeric\"] = (\n",
    "    df[\"host_response_time\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .map(response_time_mapping)\n",
    ")\n",
    "\n",
    "# Convert 'object' dtype to numeric explicitly\n",
    "df[\"host_response_time_numeric\"] = pd.to_numeric(df[\"host_response_time_numeric\"], errors='coerce')\n",
    "print(df[[\"host_response_time\", \"host_response_time_numeric\"]].dropna().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d9e7c334-fcaa-4a4f-b274-0530ec576dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make host response rate, host acceptence rate numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2f853a7a-2e46-4c09-94c0-cf2eb8bb44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove '%' and convert to numeric\n",
    "df[\"host_response_rate_numeric\"] = (\n",
    "    df[\"host_response_rate\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(\"%\", \"\", regex=False)\n",
    "    .replace(\"nan\", np.nan)  # in case of 'nan' strings\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "df[\"host_acceptance_rate_numeric\"] = (\n",
    "    df[\"host_acceptance_rate\"]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.replace(\"%\", \"\", regex=False)\n",
    "    .replace(\"nan\", np.nan)\n",
    "    .astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47efc7d5-d7cd-4fd5-bf79-5c29c0d21950",
   "metadata": {},
   "source": [
    "### Remove unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8746c331-23c7-44c4-8cb5-12698a3eef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id listing_url scrape_id last_scraped source name description neighborhood_overview picture_url host_id host_url host_name host_since host_location host_about host_response_time host_response_rate host_acceptance_rate host_is_superhost host_thumbnail_url host_picture_url host_neighbourhood host_listings_count host_total_listings_count host_verifications host_has_profile_pic host_identity_verified neighbourhood neighbourhood_cleansed neighbourhood_group_cleansed latitude longitude property_type room_type accommodates bathrooms bathrooms_text bedrooms beds amenities price minimum_nights maximum_nights minimum_minimum_nights maximum_minimum_nights minimum_maximum_nights maximum_maximum_nights minimum_nights_avg_ntm maximum_nights_avg_ntm calendar_updated has_availability availability_30 availability_60 availability_90 availability_365 calendar_last_scraped number_of_reviews number_of_reviews_ltm number_of_reviews_l30d availability_eoy number_of_reviews_ly estimated_occupancy_l365d estimated_revenue_l365d first_review last_review review_scores_rating review_scores_accuracy review_scores_cleanliness review_scores_checkin review_scores_communication review_scores_location review_scores_value license instant_bookable calculated_host_listings_count calculated_host_listings_count_entire_homes calculated_host_listings_count_private_rooms calculated_host_listings_count_shared_rooms reviews_per_month has_refrigerator refrigerator_shared refrigerator_severin refrigerator_samsung refrigerator_whirlpool refrigerator_aeg refrigerator_zanussi refrigerator_amazon refrigerator_haier refrigerator_gorenje refrigerator_teka refrigerator_panasonic refrigerator_electrolux refrigerator_beko refrigerator_neff refrigerator_vestel refrigerator_siemens refrigerator_bosch refrigerator_miele refrigerator_smeg refrigerator_gaggenau refrigerator_amica refrigerator_liebherr refrigerator_ikea refrigerator_sharp refrigerator_lg refrigerator_bomann has_oven oven_beko oven_miele oven_electrolux oven_panasonic oven_neff oven_zanussi oven_teka oven_haier oven_gaggenau oven_aeg oven_bosch oven_whirlpool oven_smeg oven_ikea oven_siemens has_stove stove_gaggenau stove_electric stove_whirlpool stove_beko stove_teka stove_miele stove_siemens stove_aeg stove_neff stove_smeg stove_gas stove_zanussi stove_electrolux stove_induction stove_ikea stove_haier stove_panasonic stove_bosch has_sound_system sound_jbl sound_denon sound_lg sound_yamaha sound_panasonic sound_sonos sound_bose sound_philips sound_pioneer sound_onkyo sound_sony sound_marshall sound_teufel sound_samsung sound_bang_olufsen has_coffee_maker coffee_espresso coffee_french_plus coffee_french_nespresso pour_over_coffee has_exercise_equipment exercise_equipment_free_weights exercise_equipment_elliptical exercise_equipment_stationary_bike exercise_equipment_yoga_mat exercise_equipment_workout_bench exercise_equipment_treadmill has_game_console ps2 ps3 ps4 ps5 xbox360 xboxone nintendoswitch wii has_tv tv_size_inch has_streaming_provider streaming_netflix streaming_amazon_prime_video streaming_apple_tv streaming_disney_plus has_clothing_storage clothing_storage_closet clothing_storage_wardrobe clothing_storage_walk_in has_parking parking_on_premises parking_off_premises parking_free_carport parking_free_driveway parking_free_garage parking_free_residential_garage parking_free_street parking_paid_garage parking_paid_lot parking_paid parking_paid_street has_outdoor outdoor_pool_shared outdoor_pool_private outdoor_dining_area outdoor_furniture outdoor_kitchen outdoor_playground has_bath_bed_game_items bath_item_shampoo bath_item_body_soap bath_item_conditioner kitchen_item_baking_sheet bed_item_bed_linens game_item_games has_wifi wifi_speed_mbps has_backyard backyard_shared backyard_fully_fenced has_balcony has_heating has_central_heating has_hottub has_bathtub has_washer washer_paid washer_in_building has_dryer dryer_paid dryer_in_building housekeeping_included housekeeping_available_at_cost baby_bath baby_monitor baby_safety children_books_and_toys crib high_chair luggage_dropoff_allowed long_term_stays_allowed air_conditioning pets_allowed ping_pong_table host_greets_you private_entrance shared_entrance workspace beach_view city_skyline_view desert_view garden_view gym_private_in_building gym_private_nearby gym_shared_in_building gym_shared_nearby gym_private gym_shared gym sqm distance_ubahn host_in_berlin longitude_neighbourhood latitude_neighbourhood host_response_time_numeric host_response_rate_numeric host_acceptance_rate_numeric "
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(c+\" \",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5f3c0824-d3c8-40e6-a5cd-c7087cf3bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    \"name\",\"description\",\"host_response_time\",\"host_response_rate\",\"host_acceptance_rate\",\"neighbourhood_group_cleansed\",\"neighbourhood_cleansed\",\"neighbourhood\",\n",
    "    \"listing_url\", \"name description\", \"host_location\",\"host_neighbourhood\",\"amenities\",\n",
    "    \"scrape_id\", \"last_scraped\", \"source\", \"neighborhood_overview\",\n",
    "    \"picture_url\", \"host_id\", \"host_url\", \"host_name\", \"host_since\",\n",
    "    \"host_about\", \"host_thumbnail_url\", \"host_picture_url\", \"host_verifications\",\n",
    "    \"bathrooms_text\", \"calendar_updated\", \"calendar_last_scraped\",\n",
    "    \"estimated_revenue_l365d\", \"first_review\", \"last_review\", \"license\",\"refrigerator_shared\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0fc9f696-30fd-4c9d-a961-5f0a160fac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[col for col in columns_to_remove if col in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fc00b7d8-114b-4ae4-829c-785fad22cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id host_is_superhost host_listings_count host_total_listings_count host_has_profile_pic host_identity_verified latitude longitude property_type room_type accommodates bathrooms bedrooms beds price minimum_nights maximum_nights minimum_minimum_nights maximum_minimum_nights minimum_maximum_nights maximum_maximum_nights minimum_nights_avg_ntm maximum_nights_avg_ntm has_availability availability_30 availability_60 availability_90 availability_365 number_of_reviews number_of_reviews_ltm number_of_reviews_l30d availability_eoy number_of_reviews_ly estimated_occupancy_l365d review_scores_rating review_scores_accuracy review_scores_cleanliness review_scores_checkin review_scores_communication review_scores_location review_scores_value instant_bookable calculated_host_listings_count calculated_host_listings_count_entire_homes calculated_host_listings_count_private_rooms calculated_host_listings_count_shared_rooms reviews_per_month has_refrigerator refrigerator_severin refrigerator_samsung refrigerator_whirlpool refrigerator_aeg refrigerator_zanussi refrigerator_amazon refrigerator_haier refrigerator_gorenje refrigerator_teka refrigerator_panasonic refrigerator_electrolux refrigerator_beko refrigerator_neff refrigerator_vestel refrigerator_siemens refrigerator_bosch refrigerator_miele refrigerator_smeg refrigerator_gaggenau refrigerator_amica refrigerator_liebherr refrigerator_ikea refrigerator_sharp refrigerator_lg refrigerator_bomann has_oven oven_beko oven_miele oven_electrolux oven_panasonic oven_neff oven_zanussi oven_teka oven_haier oven_gaggenau oven_aeg oven_bosch oven_whirlpool oven_smeg oven_ikea oven_siemens has_stove stove_gaggenau stove_electric stove_whirlpool stove_beko stove_teka stove_miele stove_siemens stove_aeg stove_neff stove_smeg stove_gas stove_zanussi stove_electrolux stove_induction stove_ikea stove_haier stove_panasonic stove_bosch has_sound_system sound_jbl sound_denon sound_lg sound_yamaha sound_panasonic sound_sonos sound_bose sound_philips sound_pioneer sound_onkyo sound_sony sound_marshall sound_teufel sound_samsung sound_bang_olufsen has_coffee_maker coffee_espresso coffee_french_plus coffee_french_nespresso pour_over_coffee has_exercise_equipment exercise_equipment_free_weights exercise_equipment_elliptical exercise_equipment_stationary_bike exercise_equipment_yoga_mat exercise_equipment_workout_bench exercise_equipment_treadmill has_game_console ps2 ps3 ps4 ps5 xbox360 xboxone nintendoswitch wii has_tv tv_size_inch has_streaming_provider streaming_netflix streaming_amazon_prime_video streaming_apple_tv streaming_disney_plus has_clothing_storage clothing_storage_closet clothing_storage_wardrobe clothing_storage_walk_in has_parking parking_on_premises parking_off_premises parking_free_carport parking_free_driveway parking_free_garage parking_free_residential_garage parking_free_street parking_paid_garage parking_paid_lot parking_paid parking_paid_street has_outdoor outdoor_pool_shared outdoor_pool_private outdoor_dining_area outdoor_furniture outdoor_kitchen outdoor_playground has_bath_bed_game_items bath_item_shampoo bath_item_body_soap bath_item_conditioner kitchen_item_baking_sheet bed_item_bed_linens game_item_games has_wifi wifi_speed_mbps has_backyard backyard_shared backyard_fully_fenced has_balcony has_heating has_central_heating has_hottub has_bathtub has_washer washer_paid washer_in_building has_dryer dryer_paid dryer_in_building housekeeping_included housekeeping_available_at_cost baby_bath baby_monitor baby_safety children_books_and_toys crib high_chair luggage_dropoff_allowed long_term_stays_allowed air_conditioning pets_allowed ping_pong_table host_greets_you private_entrance shared_entrance workspace beach_view city_skyline_view desert_view garden_view gym_private_in_building gym_private_nearby gym_shared_in_building gym_shared_nearby gym_private gym_shared gym sqm distance_ubahn host_in_berlin longitude_neighbourhood latitude_neighbourhood host_response_time_numeric host_response_rate_numeric host_acceptance_rate_numeric "
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col+\" \",end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "445b06fa-92ce-4ce6-a231-7162fbabee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"listings_detailed_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
